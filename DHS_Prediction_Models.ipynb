{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "0e8a440c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing libraries to support the data analysis \n",
    "\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from matplotlib import pyplot as plt\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from tensorflow.keras import activations\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "20b273ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing the datasets for each condition: diabetes, stroke and hypertension\n",
    "\n",
    "dd = pd.read_csv(\"diabetes_data.csv\")\n",
    "hd = pd.read_csv(\"hypertension_data.csv\")\n",
    "sd = pd.read_csv(\"stroke_data.csv\")\n",
    "\n",
    "#The hypertension dataset had some null values in the \"sex\" column. Stroke dataset had this problem too.\n",
    "#Also, the stroke dataset had some rows with the person's age below zero. These were removed, since\n",
    "#negative age doesn't make any sense.\n",
    "\n",
    "hd = hd.loc[hd['sex'].notnull()]\n",
    "sd = sd.loc[(sd['sex'].notnull()) & (sd['age'] >= 0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "00dcb243",
   "metadata": {},
   "outputs": [],
   "source": [
    "#splitting the datasets in the inputs and outputs. The outputs are binary (0 and 1), where 0 equals\n",
    "#the person not having the condition and 1 the person having the condition.\n",
    "\n",
    "dd_x_input = dd.drop(['Diabetes'], axis=1)\n",
    "dd_y_output = dd[['Diabetes']]\n",
    "\n",
    "hd_x_input = hd.drop(['target'], axis=1)\n",
    "hd_y_output = hd[['target']]\n",
    "\n",
    "sd_x_input = sd.drop(['stroke'], axis=1)\n",
    "sd_y_output = sd[['stroke']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "99346092",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now we use 30% of the input and output datasets as the testing dataset, while the remaining 70% are\n",
    "#used for training\n",
    "\n",
    "dd_X_train, dd_X_test, dd_y_train, dd_y_test = train_test_split(dd_x_input, dd_y_output, test_size=0.3, random_state = 1)\n",
    "hd_X_train, hd_X_test, hd_y_train, hd_y_test = train_test_split(hd_x_input, hd_y_output, test_size=0.3, random_state = 1)\n",
    "sd_X_train, sd_X_test, sd_y_train, sd_y_test = train_test_split(sd_x_input, sd_y_output, test_size=0.3, random_state = 1)\n",
    "\n",
    "#we scale the datasets for the neural networks (z-score normalization was used). Neural networks compare\n",
    "#data across features, and when the data is scaled, the algorithm tends to converge faster. However,\n",
    "#random forest, a tree-based algorithm, does not compare data across features, not being necessary to\n",
    "#apply normalization.\n",
    "\n",
    "\n",
    "def scale_datasets(X_train, X_test):\n",
    "    standard_scaler = StandardScaler()\n",
    "    X_train_scaled = pd.DataFrame(\n",
    "        standard_scaler.fit_transform(X_train),\n",
    "        columns= X_train.columns\n",
    "    )\n",
    "    X_test_scaled = pd.DataFrame(\n",
    "        standard_scaler.transform(X_test),\n",
    "        columns = X_test.columns\n",
    "    )\n",
    "    return X_train_scaled, X_test_scaled\n",
    "\n",
    "dd_X_train_scaled, dd_X_test_scaled = scale_datasets(dd_X_train, dd_X_test)\n",
    "hd_X_train_scaled, hd_X_test_scaled = scale_datasets(hd_X_train, hd_X_test)\n",
    "sd_X_train_scaled, sd_X_test_scaled = scale_datasets(sd_X_train, sd_X_test)\n",
    "\n",
    "dd_X_train_scaled = np.array(dd_X_train_scaled)\n",
    "dd_X_test_scaled = np.array(dd_X_test_scaled)\n",
    "dd_y_train = np.array(dd_y_train)\n",
    "dd_y_test = np.array(dd_y_test)\n",
    "\n",
    "hd_X_train_scaled = np.array(hd_X_train_scaled)\n",
    "hd_X_test_scaled = np.array(hd_X_test_scaled)\n",
    "hd_y_train = np.array(hd_y_train)\n",
    "hd_y_test = np.array(hd_y_test)\n",
    "\n",
    "sd_X_train_scaled = np.array(sd_X_train_scaled)\n",
    "sd_X_test_scaled = np.array(sd_X_test_scaled)\n",
    "sd_y_train = np.array(sd_y_train)\n",
    "sd_y_test = np.array(sd_y_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "dc80103f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "1315/1315 [==============================] - 9s 3ms/step - loss: 0.5296 - accuracy: 0.7361 - val_loss: 0.5093 - val_accuracy: 0.7508\n",
      "Epoch 2/150\n",
      "1315/1315 [==============================] - 3s 2ms/step - loss: 0.5119 - accuracy: 0.7455 - val_loss: 0.5065 - val_accuracy: 0.7521\n",
      "Epoch 3/150\n",
      "1315/1315 [==============================] - 3s 2ms/step - loss: 0.5094 - accuracy: 0.7478 - val_loss: 0.5051 - val_accuracy: 0.7512\n",
      "Epoch 4/150\n",
      "1315/1315 [==============================] - 2s 2ms/step - loss: 0.5079 - accuracy: 0.7479 - val_loss: 0.5050 - val_accuracy: 0.7504\n",
      "Epoch 5/150\n",
      "1315/1315 [==============================] - 2s 2ms/step - loss: 0.5066 - accuracy: 0.7496 - val_loss: 0.5040 - val_accuracy: 0.7497\n",
      "Epoch 6/150\n",
      "1315/1315 [==============================] - 2s 2ms/step - loss: 0.5057 - accuracy: 0.7504 - val_loss: 0.5041 - val_accuracy: 0.7497\n",
      "Epoch 7/150\n",
      "1315/1315 [==============================] - 3s 2ms/step - loss: 0.5050 - accuracy: 0.7503 - val_loss: 0.5039 - val_accuracy: 0.7481\n",
      "Epoch 8/150\n",
      "1315/1315 [==============================] - 2s 2ms/step - loss: 0.5044 - accuracy: 0.7508 - val_loss: 0.5037 - val_accuracy: 0.7496\n",
      "Epoch 9/150\n",
      "1315/1315 [==============================] - 3s 2ms/step - loss: 0.5040 - accuracy: 0.7512 - val_loss: 0.5036 - val_accuracy: 0.7505\n",
      "Epoch 10/150\n",
      "1315/1315 [==============================] - 2s 2ms/step - loss: 0.5037 - accuracy: 0.7511 - val_loss: 0.5040 - val_accuracy: 0.7481\n",
      "Epoch 11/150\n",
      "1315/1315 [==============================] - 2s 2ms/step - loss: 0.5033 - accuracy: 0.7522 - val_loss: 0.5041 - val_accuracy: 0.7493\n",
      "Epoch 12/150\n",
      "1315/1315 [==============================] - 2s 2ms/step - loss: 0.5030 - accuracy: 0.7516 - val_loss: 0.5040 - val_accuracy: 0.7490\n",
      "Epoch 13/150\n",
      "1315/1315 [==============================] - 2s 2ms/step - loss: 0.5026 - accuracy: 0.7523 - val_loss: 0.5040 - val_accuracy: 0.7498\n",
      "Epoch 14/150\n",
      "1315/1315 [==============================] - 2s 2ms/step - loss: 0.5025 - accuracy: 0.7524 - val_loss: 0.5041 - val_accuracy: 0.7510\n",
      "Epoch 15/150\n",
      "1315/1315 [==============================] - 2s 2ms/step - loss: 0.5022 - accuracy: 0.7526 - val_loss: 0.5039 - val_accuracy: 0.7509\n",
      "Epoch 16/150\n",
      "1315/1315 [==============================] - 2s 2ms/step - loss: 0.5020 - accuracy: 0.7527 - val_loss: 0.5035 - val_accuracy: 0.7523\n",
      "Epoch 17/150\n",
      "1315/1315 [==============================] - 3s 2ms/step - loss: 0.5019 - accuracy: 0.7524 - val_loss: 0.5032 - val_accuracy: 0.7524\n",
      "Epoch 18/150\n",
      "1315/1315 [==============================] - 3s 2ms/step - loss: 0.5018 - accuracy: 0.7525 - val_loss: 0.5034 - val_accuracy: 0.7540\n",
      "Epoch 19/150\n",
      "1315/1315 [==============================] - 3s 2ms/step - loss: 0.5015 - accuracy: 0.7527 - val_loss: 0.5035 - val_accuracy: 0.7536\n",
      "Epoch 20/150\n",
      "1315/1315 [==============================] - 2s 2ms/step - loss: 0.5014 - accuracy: 0.7528 - val_loss: 0.5039 - val_accuracy: 0.7533\n",
      "Epoch 21/150\n",
      "1315/1315 [==============================] - 2s 2ms/step - loss: 0.5012 - accuracy: 0.7524 - val_loss: 0.5037 - val_accuracy: 0.7551\n",
      "Epoch 22/150\n",
      "1315/1315 [==============================] - 2s 2ms/step - loss: 0.5011 - accuracy: 0.7528 - val_loss: 0.5040 - val_accuracy: 0.7535\n",
      "Epoch 23/150\n",
      "1315/1315 [==============================] - 2s 2ms/step - loss: 0.5009 - accuracy: 0.7531 - val_loss: 0.5040 - val_accuracy: 0.7536\n",
      "Epoch 24/150\n",
      "1315/1315 [==============================] - 2s 2ms/step - loss: 0.5009 - accuracy: 0.7526 - val_loss: 0.5045 - val_accuracy: 0.7540\n",
      "Epoch 25/150\n",
      "1315/1315 [==============================] - 2s 2ms/step - loss: 0.5007 - accuracy: 0.7524 - val_loss: 0.5044 - val_accuracy: 0.7531\n",
      "Epoch 26/150\n",
      "1315/1315 [==============================] - 2s 2ms/step - loss: 0.5007 - accuracy: 0.7521 - val_loss: 0.5044 - val_accuracy: 0.7533\n",
      "Epoch 27/150\n",
      "1315/1315 [==============================] - 2s 2ms/step - loss: 0.5006 - accuracy: 0.7523 - val_loss: 0.5047 - val_accuracy: 0.7547\n",
      "Epoch 28/150\n",
      "1315/1315 [==============================] - 2s 2ms/step - loss: 0.5003 - accuracy: 0.7523 - val_loss: 0.5049 - val_accuracy: 0.7540\n",
      "Epoch 29/150\n",
      "1315/1315 [==============================] - 2s 2ms/step - loss: 0.5002 - accuracy: 0.7527 - val_loss: 0.5048 - val_accuracy: 0.7543\n",
      "Epoch 30/150\n",
      "1315/1315 [==============================] - 3s 2ms/step - loss: 0.5001 - accuracy: 0.7528 - val_loss: 0.5052 - val_accuracy: 0.7537\n",
      "Epoch 31/150\n",
      "1315/1315 [==============================] - 2s 2ms/step - loss: 0.4999 - accuracy: 0.7526 - val_loss: 0.5059 - val_accuracy: 0.7544\n",
      "Epoch 32/150\n",
      "1315/1315 [==============================] - 2s 2ms/step - loss: 0.4997 - accuracy: 0.7529 - val_loss: 0.5059 - val_accuracy: 0.7529\n",
      "Epoch 33/150\n",
      "1315/1315 [==============================] - 2s 2ms/step - loss: 0.4997 - accuracy: 0.7526 - val_loss: 0.5062 - val_accuracy: 0.7537\n",
      "Epoch 34/150\n",
      "1315/1315 [==============================] - 2s 2ms/step - loss: 0.4996 - accuracy: 0.7522 - val_loss: 0.5060 - val_accuracy: 0.7539\n",
      "Epoch 35/150\n",
      "1315/1315 [==============================] - 2s 2ms/step - loss: 0.4995 - accuracy: 0.7526 - val_loss: 0.5067 - val_accuracy: 0.7540\n",
      "Epoch 36/150\n",
      "1315/1315 [==============================] - 2s 2ms/step - loss: 0.4993 - accuracy: 0.7527 - val_loss: 0.5069 - val_accuracy: 0.7532\n",
      "Epoch 37/150\n",
      "1315/1315 [==============================] - 2s 2ms/step - loss: 0.4993 - accuracy: 0.7525 - val_loss: 0.5066 - val_accuracy: 0.7527\n",
      "Epoch 38/150\n",
      "1315/1315 [==============================] - 2s 2ms/step - loss: 0.4991 - accuracy: 0.7530 - val_loss: 0.5076 - val_accuracy: 0.7529\n",
      "Epoch 39/150\n",
      "1315/1315 [==============================] - 2s 2ms/step - loss: 0.4990 - accuracy: 0.7527 - val_loss: 0.5080 - val_accuracy: 0.7516\n",
      "Epoch 40/150\n",
      "1315/1315 [==============================] - 2s 2ms/step - loss: 0.4989 - accuracy: 0.7530 - val_loss: 0.5081 - val_accuracy: 0.7524\n",
      "Epoch 41/150\n",
      "1315/1315 [==============================] - 2s 2ms/step - loss: 0.4988 - accuracy: 0.7532 - val_loss: 0.5076 - val_accuracy: 0.7527\n",
      "Epoch 42/150\n",
      "1315/1315 [==============================] - 2s 2ms/step - loss: 0.4985 - accuracy: 0.7532 - val_loss: 0.5083 - val_accuracy: 0.7525\n",
      "Epoch 43/150\n",
      "1315/1315 [==============================] - 2s 2ms/step - loss: 0.4986 - accuracy: 0.7534 - val_loss: 0.5089 - val_accuracy: 0.7528\n",
      "Epoch 44/150\n",
      "1315/1315 [==============================] - 2s 2ms/step - loss: 0.4984 - accuracy: 0.7531 - val_loss: 0.5081 - val_accuracy: 0.7543\n",
      "Epoch 45/150\n",
      "1315/1315 [==============================] - 2s 2ms/step - loss: 0.4984 - accuracy: 0.7530 - val_loss: 0.5080 - val_accuracy: 0.7521\n",
      "Epoch 46/150\n",
      "1315/1315 [==============================] - 2s 2ms/step - loss: 0.4982 - accuracy: 0.7534 - val_loss: 0.5087 - val_accuracy: 0.7517\n",
      "Epoch 47/150\n",
      "1315/1315 [==============================] - 2s 2ms/step - loss: 0.4981 - accuracy: 0.7533 - val_loss: 0.5078 - val_accuracy: 0.7517\n",
      "Epoch 48/150\n",
      "1315/1315 [==============================] - 2s 2ms/step - loss: 0.4981 - accuracy: 0.7531 - val_loss: 0.5088 - val_accuracy: 0.7532\n",
      "Epoch 49/150\n",
      "1315/1315 [==============================] - 2s 2ms/step - loss: 0.4980 - accuracy: 0.7528 - val_loss: 0.5093 - val_accuracy: 0.7532\n",
      "Epoch 50/150\n",
      "1315/1315 [==============================] - 2s 2ms/step - loss: 0.4980 - accuracy: 0.7533 - val_loss: 0.5100 - val_accuracy: 0.7525\n",
      "Epoch 51/150\n",
      "1315/1315 [==============================] - 2s 2ms/step - loss: 0.4979 - accuracy: 0.7525 - val_loss: 0.5100 - val_accuracy: 0.7471\n",
      "Epoch 52/150\n",
      "1315/1315 [==============================] - 2s 2ms/step - loss: 0.4978 - accuracy: 0.7530 - val_loss: 0.5104 - val_accuracy: 0.7520\n",
      "Epoch 53/150\n",
      "1315/1315 [==============================] - 2s 2ms/step - loss: 0.4977 - accuracy: 0.7525 - val_loss: 0.5103 - val_accuracy: 0.7459\n",
      "Epoch 54/150\n",
      "1315/1315 [==============================] - 2s 2ms/step - loss: 0.4977 - accuracy: 0.7537 - val_loss: 0.5098 - val_accuracy: 0.7474\n",
      "Epoch 55/150\n",
      "1315/1315 [==============================] - 2s 2ms/step - loss: 0.4976 - accuracy: 0.7543 - val_loss: 0.5100 - val_accuracy: 0.7465\n",
      "Epoch 56/150\n",
      "1315/1315 [==============================] - 2s 2ms/step - loss: 0.4975 - accuracy: 0.7540 - val_loss: 0.5113 - val_accuracy: 0.7453\n",
      "Epoch 57/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1315/1315 [==============================] - 2s 2ms/step - loss: 0.4974 - accuracy: 0.7539 - val_loss: 0.5111 - val_accuracy: 0.7466\n",
      "Epoch 58/150\n",
      "1315/1315 [==============================] - 2s 2ms/step - loss: 0.4973 - accuracy: 0.7536 - val_loss: 0.5115 - val_accuracy: 0.7517\n",
      "Epoch 59/150\n",
      "1315/1315 [==============================] - 2s 2ms/step - loss: 0.4974 - accuracy: 0.7535 - val_loss: 0.5102 - val_accuracy: 0.7529\n",
      "Epoch 60/150\n",
      "1315/1315 [==============================] - 2s 2ms/step - loss: 0.4974 - accuracy: 0.7535 - val_loss: 0.5097 - val_accuracy: 0.7533\n",
      "Epoch 61/150\n",
      "1315/1315 [==============================] - 2s 2ms/step - loss: 0.4971 - accuracy: 0.7537 - val_loss: 0.5089 - val_accuracy: 0.7520\n",
      "Epoch 62/150\n",
      "1315/1315 [==============================] - 2s 2ms/step - loss: 0.4972 - accuracy: 0.7537 - val_loss: 0.5096 - val_accuracy: 0.7527\n",
      "Epoch 63/150\n",
      "1315/1315 [==============================] - 2s 2ms/step - loss: 0.4972 - accuracy: 0.7532 - val_loss: 0.5105 - val_accuracy: 0.7531\n",
      "Epoch 64/150\n",
      "1315/1315 [==============================] - 2s 2ms/step - loss: 0.4970 - accuracy: 0.7535 - val_loss: 0.5097 - val_accuracy: 0.7533\n",
      "Epoch 65/150\n",
      "1315/1315 [==============================] - 2s 2ms/step - loss: 0.4968 - accuracy: 0.7532 - val_loss: 0.5088 - val_accuracy: 0.7529\n",
      "Epoch 66/150\n",
      "1315/1315 [==============================] - 2s 2ms/step - loss: 0.4969 - accuracy: 0.7541 - val_loss: 0.5100 - val_accuracy: 0.7520\n",
      "Epoch 67/150\n",
      "1315/1315 [==============================] - 2s 2ms/step - loss: 0.4966 - accuracy: 0.7542 - val_loss: 0.5104 - val_accuracy: 0.7516\n",
      "Epoch 68/150\n",
      "1315/1315 [==============================] - 2s 2ms/step - loss: 0.4965 - accuracy: 0.7543 - val_loss: 0.5111 - val_accuracy: 0.7519\n",
      "Epoch 69/150\n",
      "1315/1315 [==============================] - 2s 2ms/step - loss: 0.4965 - accuracy: 0.7537 - val_loss: 0.5104 - val_accuracy: 0.7528\n",
      "Epoch 70/150\n",
      "1315/1315 [==============================] - 2s 2ms/step - loss: 0.4964 - accuracy: 0.7543 - val_loss: 0.5118 - val_accuracy: 0.7523\n",
      "Epoch 71/150\n",
      "1315/1315 [==============================] - 2s 2ms/step - loss: 0.4964 - accuracy: 0.7544 - val_loss: 0.5117 - val_accuracy: 0.7524\n",
      "Epoch 72/150\n",
      "1315/1315 [==============================] - 2s 2ms/step - loss: 0.4966 - accuracy: 0.7540 - val_loss: 0.5116 - val_accuracy: 0.7517\n",
      "Epoch 73/150\n",
      "1315/1315 [==============================] - 2s 2ms/step - loss: 0.4964 - accuracy: 0.7541 - val_loss: 0.5121 - val_accuracy: 0.7517\n",
      "Epoch 74/150\n",
      "1315/1315 [==============================] - 2s 2ms/step - loss: 0.4966 - accuracy: 0.7537 - val_loss: 0.5122 - val_accuracy: 0.7524\n",
      "Epoch 75/150\n",
      "1315/1315 [==============================] - 2s 2ms/step - loss: 0.4964 - accuracy: 0.7534 - val_loss: 0.5123 - val_accuracy: 0.7517\n",
      "Epoch 76/150\n",
      "1315/1315 [==============================] - 2s 2ms/step - loss: 0.4962 - accuracy: 0.7544 - val_loss: 0.5125 - val_accuracy: 0.7514\n",
      "Epoch 77/150\n",
      "1315/1315 [==============================] - 2s 2ms/step - loss: 0.4962 - accuracy: 0.7547 - val_loss: 0.5134 - val_accuracy: 0.7506\n",
      "Epoch 78/150\n",
      "1315/1315 [==============================] - 2s 2ms/step - loss: 0.4965 - accuracy: 0.7540 - val_loss: 0.5128 - val_accuracy: 0.7521\n",
      "Epoch 79/150\n",
      "1315/1315 [==============================] - 2s 2ms/step - loss: 0.4963 - accuracy: 0.7539 - val_loss: 0.5124 - val_accuracy: 0.7525\n",
      "Epoch 80/150\n",
      "1315/1315 [==============================] - 2s 2ms/step - loss: 0.4963 - accuracy: 0.7534 - val_loss: 0.5135 - val_accuracy: 0.7528\n",
      "Epoch 81/150\n",
      "1315/1315 [==============================] - 2s 2ms/step - loss: 0.4960 - accuracy: 0.7545 - val_loss: 0.5123 - val_accuracy: 0.7525\n",
      "Epoch 82/150\n",
      "1315/1315 [==============================] - 2s 2ms/step - loss: 0.4959 - accuracy: 0.7543 - val_loss: 0.5123 - val_accuracy: 0.7525\n",
      "Epoch 83/150\n",
      "1315/1315 [==============================] - 2s 2ms/step - loss: 0.4960 - accuracy: 0.7537 - val_loss: 0.5126 - val_accuracy: 0.7531\n",
      "Epoch 84/150\n",
      "1315/1315 [==============================] - 2s 2ms/step - loss: 0.4958 - accuracy: 0.7546 - val_loss: 0.5120 - val_accuracy: 0.7528\n",
      "Epoch 85/150\n",
      "1315/1315 [==============================] - 2s 2ms/step - loss: 0.4959 - accuracy: 0.7544 - val_loss: 0.5117 - val_accuracy: 0.7536\n",
      "Epoch 86/150\n",
      "1315/1315 [==============================] - 3s 2ms/step - loss: 0.4957 - accuracy: 0.7539 - val_loss: 0.5122 - val_accuracy: 0.7544\n",
      "Epoch 87/150\n",
      "1315/1315 [==============================] - 2s 2ms/step - loss: 0.4956 - accuracy: 0.7548 - val_loss: 0.5123 - val_accuracy: 0.7539\n",
      "Epoch 88/150\n",
      "1315/1315 [==============================] - 3s 2ms/step - loss: 0.4956 - accuracy: 0.7542 - val_loss: 0.5125 - val_accuracy: 0.7524\n",
      "Epoch 89/150\n",
      "1315/1315 [==============================] - 3s 2ms/step - loss: 0.4955 - accuracy: 0.7541 - val_loss: 0.5133 - val_accuracy: 0.7527\n",
      "Epoch 90/150\n",
      "1315/1315 [==============================] - 3s 2ms/step - loss: 0.4957 - accuracy: 0.7543 - val_loss: 0.5120 - val_accuracy: 0.7532\n",
      "Epoch 91/150\n",
      "1315/1315 [==============================] - 3s 2ms/step - loss: 0.4957 - accuracy: 0.7540 - val_loss: 0.5110 - val_accuracy: 0.7532\n",
      "Epoch 92/150\n",
      "1315/1315 [==============================] - 2s 2ms/step - loss: 0.4957 - accuracy: 0.7539 - val_loss: 0.5109 - val_accuracy: 0.7540\n",
      "Epoch 93/150\n",
      "1315/1315 [==============================] - 2s 2ms/step - loss: 0.4957 - accuracy: 0.7537 - val_loss: 0.5121 - val_accuracy: 0.7533\n",
      "Epoch 94/150\n",
      "1315/1315 [==============================] - 2s 2ms/step - loss: 0.4958 - accuracy: 0.7545 - val_loss: 0.5116 - val_accuracy: 0.7521\n",
      "Epoch 95/150\n",
      "1315/1315 [==============================] - 2s 2ms/step - loss: 0.4958 - accuracy: 0.7543 - val_loss: 0.5118 - val_accuracy: 0.7514\n",
      "Epoch 96/150\n",
      "1315/1315 [==============================] - 2s 2ms/step - loss: 0.4954 - accuracy: 0.7544 - val_loss: 0.5128 - val_accuracy: 0.7519\n",
      "Epoch 97/150\n",
      "1315/1315 [==============================] - 2s 2ms/step - loss: 0.4956 - accuracy: 0.7543 - val_loss: 0.5113 - val_accuracy: 0.7528\n",
      "Epoch 98/150\n",
      "1315/1315 [==============================] - 2s 2ms/step - loss: 0.4955 - accuracy: 0.7536 - val_loss: 0.5115 - val_accuracy: 0.7502\n",
      "Epoch 99/150\n",
      "1315/1315 [==============================] - 2s 2ms/step - loss: 0.4952 - accuracy: 0.7546 - val_loss: 0.5124 - val_accuracy: 0.7510\n",
      "Epoch 100/150\n",
      "1315/1315 [==============================] - 2s 2ms/step - loss: 0.4957 - accuracy: 0.7539 - val_loss: 0.5108 - val_accuracy: 0.7544\n",
      "Epoch 101/150\n",
      "1315/1315 [==============================] - 2s 2ms/step - loss: 0.4958 - accuracy: 0.7537 - val_loss: 0.5116 - val_accuracy: 0.7512\n",
      "Epoch 102/150\n",
      "1315/1315 [==============================] - 3s 2ms/step - loss: 0.4958 - accuracy: 0.7535 - val_loss: 0.5127 - val_accuracy: 0.7516\n",
      "Epoch 103/150\n",
      "1315/1315 [==============================] - 2s 2ms/step - loss: 0.4961 - accuracy: 0.7542 - val_loss: 0.5110 - val_accuracy: 0.7512\n",
      "Epoch 104/150\n",
      "1315/1315 [==============================] - 2s 2ms/step - loss: 0.4958 - accuracy: 0.7545 - val_loss: 0.5113 - val_accuracy: 0.7529\n",
      "Epoch 105/150\n",
      "1315/1315 [==============================] - 2s 2ms/step - loss: 0.4953 - accuracy: 0.7549 - val_loss: 0.5121 - val_accuracy: 0.7512\n",
      "Epoch 106/150\n",
      "1315/1315 [==============================] - 2s 2ms/step - loss: 0.4952 - accuracy: 0.7549 - val_loss: 0.5117 - val_accuracy: 0.7505\n",
      "Epoch 107/150\n",
      "1315/1315 [==============================] - 2s 2ms/step - loss: 0.4952 - accuracy: 0.7544 - val_loss: 0.5119 - val_accuracy: 0.7523\n",
      "Epoch 108/150\n",
      "1315/1315 [==============================] - 2s 2ms/step - loss: 0.4951 - accuracy: 0.7554 - val_loss: 0.5129 - val_accuracy: 0.7525\n",
      "Epoch 109/150\n",
      "1315/1315 [==============================] - 2s 2ms/step - loss: 0.4954 - accuracy: 0.7556 - val_loss: 0.5126 - val_accuracy: 0.7532\n",
      "Epoch 110/150\n",
      "1315/1315 [==============================] - 2s 2ms/step - loss: 0.4951 - accuracy: 0.7557 - val_loss: 0.5115 - val_accuracy: 0.7540\n",
      "Epoch 111/150\n",
      "1315/1315 [==============================] - 2s 2ms/step - loss: 0.4953 - accuracy: 0.7555 - val_loss: 0.5105 - val_accuracy: 0.7527\n",
      "Epoch 112/150\n",
      "1315/1315 [==============================] - 2s 2ms/step - loss: 0.4949 - accuracy: 0.7549 - val_loss: 0.5118 - val_accuracy: 0.7528\n",
      "Epoch 113/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1315/1315 [==============================] - 2s 2ms/step - loss: 0.4953 - accuracy: 0.7553 - val_loss: 0.5124 - val_accuracy: 0.7525\n",
      "Epoch 114/150\n",
      "1315/1315 [==============================] - 2s 2ms/step - loss: 0.4946 - accuracy: 0.7563 - val_loss: 0.5111 - val_accuracy: 0.7543\n",
      "Epoch 115/150\n",
      "1315/1315 [==============================] - 2s 2ms/step - loss: 0.4951 - accuracy: 0.7558 - val_loss: 0.5118 - val_accuracy: 0.7521\n",
      "Epoch 116/150\n",
      "1315/1315 [==============================] - 2s 2ms/step - loss: 0.4951 - accuracy: 0.7558 - val_loss: 0.5108 - val_accuracy: 0.7527\n",
      "Epoch 117/150\n",
      "1315/1315 [==============================] - 2s 2ms/step - loss: 0.4951 - accuracy: 0.7549 - val_loss: 0.5120 - val_accuracy: 0.7517\n",
      "Epoch 118/150\n",
      "1315/1315 [==============================] - 2s 2ms/step - loss: 0.4953 - accuracy: 0.7554 - val_loss: 0.5106 - val_accuracy: 0.7531\n",
      "Epoch 119/150\n",
      "1315/1315 [==============================] - 2s 2ms/step - loss: 0.4948 - accuracy: 0.7556 - val_loss: 0.5115 - val_accuracy: 0.7531\n",
      "Epoch 120/150\n",
      "1315/1315 [==============================] - 2s 2ms/step - loss: 0.4946 - accuracy: 0.7555 - val_loss: 0.5124 - val_accuracy: 0.7531\n",
      "Epoch 121/150\n",
      "1315/1315 [==============================] - 2s 2ms/step - loss: 0.4949 - accuracy: 0.7555 - val_loss: 0.5113 - val_accuracy: 0.7545\n",
      "Epoch 122/150\n",
      "1315/1315 [==============================] - 2s 2ms/step - loss: 0.4952 - accuracy: 0.7549 - val_loss: 0.5127 - val_accuracy: 0.7521\n",
      "Epoch 123/150\n",
      "1315/1315 [==============================] - 2s 2ms/step - loss: 0.4952 - accuracy: 0.7544 - val_loss: 0.5115 - val_accuracy: 0.7523\n",
      "Epoch 124/150\n",
      "1315/1315 [==============================] - 2s 2ms/step - loss: 0.4948 - accuracy: 0.7551 - val_loss: 0.5127 - val_accuracy: 0.7527\n",
      "Epoch 125/150\n",
      "1315/1315 [==============================] - 2s 2ms/step - loss: 0.4947 - accuracy: 0.7548 - val_loss: 0.5116 - val_accuracy: 0.7539\n",
      "Epoch 126/150\n",
      "1315/1315 [==============================] - 2s 2ms/step - loss: 0.4947 - accuracy: 0.7550 - val_loss: 0.5127 - val_accuracy: 0.7509\n",
      "Epoch 127/150\n",
      "1315/1315 [==============================] - 2s 2ms/step - loss: 0.4944 - accuracy: 0.7548 - val_loss: 0.5119 - val_accuracy: 0.7531\n",
      "Epoch 128/150\n",
      "1315/1315 [==============================] - 2s 2ms/step - loss: 0.4947 - accuracy: 0.7556 - val_loss: 0.5116 - val_accuracy: 0.7529\n",
      "Epoch 129/150\n",
      "1315/1315 [==============================] - 2s 2ms/step - loss: 0.4946 - accuracy: 0.7554 - val_loss: 0.5118 - val_accuracy: 0.7531\n",
      "Epoch 130/150\n",
      "1315/1315 [==============================] - 2s 2ms/step - loss: 0.4945 - accuracy: 0.7555 - val_loss: 0.5119 - val_accuracy: 0.7504\n",
      "Epoch 131/150\n",
      "1315/1315 [==============================] - 2s 2ms/step - loss: 0.4949 - accuracy: 0.7550 - val_loss: 0.5112 - val_accuracy: 0.7540\n",
      "Epoch 132/150\n",
      "1315/1315 [==============================] - 2s 2ms/step - loss: 0.4949 - accuracy: 0.7544 - val_loss: 0.5120 - val_accuracy: 0.7529\n",
      "Epoch 133/150\n",
      "1315/1315 [==============================] - 2s 2ms/step - loss: 0.4947 - accuracy: 0.7550 - val_loss: 0.5123 - val_accuracy: 0.7523\n",
      "Epoch 134/150\n",
      "1315/1315 [==============================] - 2s 2ms/step - loss: 0.4946 - accuracy: 0.7550 - val_loss: 0.5109 - val_accuracy: 0.7536\n",
      "Epoch 135/150\n",
      "1315/1315 [==============================] - 2s 2ms/step - loss: 0.4947 - accuracy: 0.7546 - val_loss: 0.5123 - val_accuracy: 0.7519\n",
      "Epoch 136/150\n",
      "1315/1315 [==============================] - 2s 2ms/step - loss: 0.4946 - accuracy: 0.7551 - val_loss: 0.5121 - val_accuracy: 0.7547\n",
      "Epoch 137/150\n",
      "1315/1315 [==============================] - 2s 2ms/step - loss: 0.4947 - accuracy: 0.7549 - val_loss: 0.5121 - val_accuracy: 0.7519\n",
      "Epoch 138/150\n",
      "1315/1315 [==============================] - 2s 2ms/step - loss: 0.4948 - accuracy: 0.7542 - val_loss: 0.5118 - val_accuracy: 0.7532\n",
      "Epoch 139/150\n",
      "1315/1315 [==============================] - 2s 2ms/step - loss: 0.4944 - accuracy: 0.7549 - val_loss: 0.5132 - val_accuracy: 0.7513\n",
      "Epoch 140/150\n",
      "1315/1315 [==============================] - 2s 2ms/step - loss: 0.4948 - accuracy: 0.7546 - val_loss: 0.5104 - val_accuracy: 0.7523\n",
      "Epoch 141/150\n",
      "1315/1315 [==============================] - 2s 2ms/step - loss: 0.4945 - accuracy: 0.7532 - val_loss: 0.5129 - val_accuracy: 0.7505\n",
      "Epoch 142/150\n",
      "1315/1315 [==============================] - 2s 2ms/step - loss: 0.4943 - accuracy: 0.7531 - val_loss: 0.5123 - val_accuracy: 0.7529\n",
      "Epoch 143/150\n",
      "1315/1315 [==============================] - 2s 2ms/step - loss: 0.4952 - accuracy: 0.7536 - val_loss: 0.5118 - val_accuracy: 0.7528\n",
      "Epoch 144/150\n",
      "1315/1315 [==============================] - 2s 2ms/step - loss: 0.4949 - accuracy: 0.7534 - val_loss: 0.5130 - val_accuracy: 0.7529\n",
      "Epoch 145/150\n",
      "1315/1315 [==============================] - 2s 2ms/step - loss: 0.4946 - accuracy: 0.7535 - val_loss: 0.5113 - val_accuracy: 0.7519\n",
      "Epoch 146/150\n",
      "1315/1315 [==============================] - 2s 2ms/step - loss: 0.4945 - accuracy: 0.7531 - val_loss: 0.5120 - val_accuracy: 0.7496\n",
      "Epoch 147/150\n",
      "1315/1315 [==============================] - 2s 2ms/step - loss: 0.4946 - accuracy: 0.7537 - val_loss: 0.5118 - val_accuracy: 0.7508\n",
      "Epoch 148/150\n",
      "1315/1315 [==============================] - 2s 2ms/step - loss: 0.4948 - accuracy: 0.7539 - val_loss: 0.5115 - val_accuracy: 0.7494\n",
      "Epoch 149/150\n",
      "1315/1315 [==============================] - 2s 2ms/step - loss: 0.4952 - accuracy: 0.7537 - val_loss: 0.5118 - val_accuracy: 0.7466\n",
      "Epoch 150/150\n",
      "1315/1315 [==============================] - 2s 2ms/step - loss: 0.4949 - accuracy: 0.7544 - val_loss: 0.5103 - val_accuracy: 0.7479\n",
      "Accuracy for the prediction of diabetes:0.7471\n"
     ]
    }
   ],
   "source": [
    "#=============================\n",
    "#START OF ARTIFICIAL NEURAL NETWORK TESTING\n",
    "#=============================\n",
    "\n",
    "#We use the sequential package from Keras to build customizable layers for the network. \n",
    "model = Sequential()\n",
    "model.add(Dense(14, input_dim=17, activation=\"relu\"))#, kernel_regularizer=keras.regularizers.l2(0.1)))\n",
    "model.add(Dense(11, activation=\"relu\"))\n",
    "model.add(Dense(8, activation=\"relu\"))#, kernel_regularizer=keras.regularizers.l2(0.1)))\n",
    "model.add(Dense(5, activation=\"relu\"))\n",
    "model.add(Dense(2, activation=\"relu\"))#, kernel_regularizer=keras.regularizers.l2(0.1)))\n",
    "model.add(Dense(1, activation=tf.keras.activations.sigmoid))\n",
    "\n",
    "#Compiling the model previously built.\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "#Applying the model to fit the data\n",
    "history = model.fit(dd_X_train_scaled, dd_y_train, epochs=150, batch_size=32, verbose=1, validation_split = 0.15, shuffle = False)\n",
    "\n",
    "#Applying the model to the test dataset to predict outputs\n",
    "dd_y_predict = model.predict(dd_X_test_scaled)\n",
    "dd_y_predict = np.array(np.array(list(map(lambda x: 0 if x<0.5 else 1, dd_y_predict))))\n",
    "print(\"Accuracy for the prediction of diabetes:%.4f\" % accuracy_score(np.array(dd_y_test), np.array(dd_y_predict)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "02bacc0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "485/485 [==============================] - 2s 2ms/step - loss: 1.3787 - accuracy: 0.6389 - val_loss: 0.6848 - val_accuracy: 0.8509\n",
      "Epoch 2/150\n",
      "485/485 [==============================] - 1s 2ms/step - loss: 0.5621 - accuracy: 0.8557 - val_loss: 0.4919 - val_accuracy: 0.8706\n",
      "Epoch 3/150\n",
      "485/485 [==============================] - 1s 2ms/step - loss: 0.4638 - accuracy: 0.8804 - val_loss: 0.4369 - val_accuracy: 0.8827\n",
      "Epoch 4/150\n",
      "485/485 [==============================] - 1s 2ms/step - loss: 0.4219 - accuracy: 0.8904 - val_loss: 0.4042 - val_accuracy: 0.8911\n",
      "Epoch 5/150\n",
      "485/485 [==============================] - 1s 2ms/step - loss: 0.3910 - accuracy: 0.8954 - val_loss: 0.3780 - val_accuracy: 0.8867\n",
      "Epoch 6/150\n",
      "485/485 [==============================] - 1s 2ms/step - loss: 0.3634 - accuracy: 0.9024 - val_loss: 0.3528 - val_accuracy: 0.9075\n",
      "Epoch 7/150\n",
      "485/485 [==============================] - 1s 2ms/step - loss: 0.3346 - accuracy: 0.9091 - val_loss: 0.3137 - val_accuracy: 0.9185\n",
      "Epoch 8/150\n",
      "485/485 [==============================] - 1s 2ms/step - loss: 0.3082 - accuracy: 0.9194 - val_loss: 0.2913 - val_accuracy: 0.9302\n",
      "Epoch 9/150\n",
      "485/485 [==============================] - 1s 2ms/step - loss: 0.2933 - accuracy: 0.9263 - val_loss: 0.2771 - val_accuracy: 0.9346\n",
      "Epoch 10/150\n",
      "485/485 [==============================] - 1s 2ms/step - loss: 0.2826 - accuracy: 0.9303 - val_loss: 0.2661 - val_accuracy: 0.9364\n",
      "Epoch 11/150\n",
      "485/485 [==============================] - 1s 2ms/step - loss: 0.2736 - accuracy: 0.9340 - val_loss: 0.2568 - val_accuracy: 0.9415\n",
      "Epoch 12/150\n",
      "485/485 [==============================] - 1s 3ms/step - loss: 0.2659 - accuracy: 0.9359 - val_loss: 0.2492 - val_accuracy: 0.9448\n",
      "Epoch 13/150\n",
      "485/485 [==============================] - 1s 2ms/step - loss: 0.2590 - accuracy: 0.9380 - val_loss: 0.2417 - val_accuracy: 0.9459\n",
      "Epoch 14/150\n",
      "485/485 [==============================] - 1s 2ms/step - loss: 0.2507 - accuracy: 0.9399 - val_loss: 0.2325 - val_accuracy: 0.9496\n",
      "Epoch 15/150\n",
      "485/485 [==============================] - 1s 2ms/step - loss: 0.2438 - accuracy: 0.9423 - val_loss: 0.2285 - val_accuracy: 0.9499\n",
      "Epoch 16/150\n",
      "485/485 [==============================] - 1s 2ms/step - loss: 0.2385 - accuracy: 0.9443 - val_loss: 0.2239 - val_accuracy: 0.9518\n",
      "Epoch 17/150\n",
      "485/485 [==============================] - 1s 2ms/step - loss: 0.2337 - accuracy: 0.9453 - val_loss: 0.2206 - val_accuracy: 0.9539\n",
      "Epoch 18/150\n",
      "485/485 [==============================] - 1s 2ms/step - loss: 0.2299 - accuracy: 0.9458 - val_loss: 0.2163 - val_accuracy: 0.9554\n",
      "Epoch 19/150\n",
      "485/485 [==============================] - 1s 2ms/step - loss: 0.2264 - accuracy: 0.9465 - val_loss: 0.2139 - val_accuracy: 0.9580\n",
      "Epoch 20/150\n",
      "485/485 [==============================] - 1s 2ms/step - loss: 0.2224 - accuracy: 0.9480 - val_loss: 0.2110 - val_accuracy: 0.9580\n",
      "Epoch 21/150\n",
      "485/485 [==============================] - 1s 2ms/step - loss: 0.2199 - accuracy: 0.9487 - val_loss: 0.2057 - val_accuracy: 0.9594\n",
      "Epoch 22/150\n",
      "485/485 [==============================] - 1s 2ms/step - loss: 0.2084 - accuracy: 0.9525 - val_loss: 0.2065 - val_accuracy: 0.9583\n",
      "Epoch 23/150\n",
      "485/485 [==============================] - 1s 2ms/step - loss: 0.1866 - accuracy: 0.9616 - val_loss: 0.1806 - val_accuracy: 0.9700\n",
      "Epoch 24/150\n",
      "485/485 [==============================] - 1s 2ms/step - loss: 0.1761 - accuracy: 0.9668 - val_loss: 0.1799 - val_accuracy: 0.9664\n",
      "Epoch 25/150\n",
      "485/485 [==============================] - 1s 2ms/step - loss: 0.1713 - accuracy: 0.9684 - val_loss: 0.1741 - val_accuracy: 0.9708\n",
      "Epoch 26/150\n",
      "485/485 [==============================] - 2s 4ms/step - loss: 0.1668 - accuracy: 0.9707 - val_loss: 0.1637 - val_accuracy: 0.9759\n",
      "Epoch 27/150\n",
      "485/485 [==============================] - 1s 2ms/step - loss: 0.1654 - accuracy: 0.9702 - val_loss: 0.1712 - val_accuracy: 0.9708\n",
      "Epoch 28/150\n",
      "485/485 [==============================] - 1s 2ms/step - loss: 0.1624 - accuracy: 0.9707 - val_loss: 0.1631 - val_accuracy: 0.9733\n",
      "Epoch 29/150\n",
      "485/485 [==============================] - 1s 2ms/step - loss: 0.1588 - accuracy: 0.9734 - val_loss: 0.1602 - val_accuracy: 0.9744\n",
      "Epoch 30/150\n",
      "485/485 [==============================] - 1s 2ms/step - loss: 0.1572 - accuracy: 0.9740 - val_loss: 0.1596 - val_accuracy: 0.9726\n",
      "Epoch 31/150\n",
      "485/485 [==============================] - 1s 2ms/step - loss: 0.1565 - accuracy: 0.9742 - val_loss: 0.1611 - val_accuracy: 0.9773\n",
      "Epoch 32/150\n",
      "485/485 [==============================] - 1s 2ms/step - loss: 0.1550 - accuracy: 0.9739 - val_loss: 0.1573 - val_accuracy: 0.9770\n",
      "Epoch 33/150\n",
      "485/485 [==============================] - 1s 2ms/step - loss: 0.1521 - accuracy: 0.9747 - val_loss: 0.1530 - val_accuracy: 0.9781\n",
      "Epoch 34/150\n",
      "485/485 [==============================] - 1s 2ms/step - loss: 0.1489 - accuracy: 0.9758 - val_loss: 0.1522 - val_accuracy: 0.9777\n",
      "Epoch 35/150\n",
      "485/485 [==============================] - 1s 2ms/step - loss: 0.1482 - accuracy: 0.9757 - val_loss: 0.1464 - val_accuracy: 0.9795\n",
      "Epoch 36/150\n",
      "485/485 [==============================] - 1s 2ms/step - loss: 0.1467 - accuracy: 0.9761 - val_loss: 0.1513 - val_accuracy: 0.9766\n",
      "Epoch 37/150\n",
      "485/485 [==============================] - 1s 2ms/step - loss: 0.1455 - accuracy: 0.9765 - val_loss: 0.1468 - val_accuracy: 0.9792\n",
      "Epoch 38/150\n",
      "485/485 [==============================] - 1s 2ms/step - loss: 0.1438 - accuracy: 0.9768 - val_loss: 0.1433 - val_accuracy: 0.9803\n",
      "Epoch 39/150\n",
      "485/485 [==============================] - 1s 2ms/step - loss: 0.1419 - accuracy: 0.9779 - val_loss: 0.1438 - val_accuracy: 0.9817\n",
      "Epoch 40/150\n",
      "485/485 [==============================] - 1s 2ms/step - loss: 0.1393 - accuracy: 0.9783 - val_loss: 0.1406 - val_accuracy: 0.9821\n",
      "Epoch 41/150\n",
      "485/485 [==============================] - 1s 2ms/step - loss: 0.1422 - accuracy: 0.9768 - val_loss: 0.1473 - val_accuracy: 0.9733\n",
      "Epoch 42/150\n",
      "485/485 [==============================] - 1s 2ms/step - loss: 0.1364 - accuracy: 0.9790 - val_loss: 0.1320 - val_accuracy: 0.9810\n",
      "Epoch 43/150\n",
      "485/485 [==============================] - 1s 3ms/step - loss: 0.1365 - accuracy: 0.9786 - val_loss: 0.1311 - val_accuracy: 0.9832\n",
      "Epoch 44/150\n",
      "485/485 [==============================] - 1s 2ms/step - loss: 0.1449 - accuracy: 0.9744 - val_loss: 0.1448 - val_accuracy: 0.9751\n",
      "Epoch 45/150\n",
      "485/485 [==============================] - 1s 2ms/step - loss: 0.1305 - accuracy: 0.9816 - val_loss: 0.1281 - val_accuracy: 0.9795\n",
      "Epoch 46/150\n",
      "485/485 [==============================] - 1s 3ms/step - loss: 0.1324 - accuracy: 0.9801 - val_loss: 0.1299 - val_accuracy: 0.9821\n",
      "Epoch 47/150\n",
      "485/485 [==============================] - 1s 3ms/step - loss: 0.1331 - accuracy: 0.9790 - val_loss: 0.1303 - val_accuracy: 0.9792\n",
      "Epoch 48/150\n",
      "485/485 [==============================] - 1s 2ms/step - loss: 0.1345 - accuracy: 0.9783 - val_loss: 0.1450 - val_accuracy: 0.9770\n",
      "Epoch 49/150\n",
      "485/485 [==============================] - 1s 3ms/step - loss: 0.1334 - accuracy: 0.9783 - val_loss: 0.1461 - val_accuracy: 0.9726\n",
      "Epoch 50/150\n",
      "485/485 [==============================] - 1s 2ms/step - loss: 0.1305 - accuracy: 0.9801 - val_loss: 0.1335 - val_accuracy: 0.9828\n",
      "Epoch 51/150\n",
      "485/485 [==============================] - 1s 2ms/step - loss: 0.1279 - accuracy: 0.9809 - val_loss: 0.1294 - val_accuracy: 0.9803\n",
      "Epoch 52/150\n",
      "485/485 [==============================] - 1s 2ms/step - loss: 0.1257 - accuracy: 0.9817 - val_loss: 0.1581 - val_accuracy: 0.9715\n",
      "Epoch 53/150\n",
      "485/485 [==============================] - 1s 2ms/step - loss: 0.1360 - accuracy: 0.9768 - val_loss: 0.1221 - val_accuracy: 0.9817\n",
      "Epoch 54/150\n",
      "485/485 [==============================] - 1s 2ms/step - loss: 0.1357 - accuracy: 0.9770 - val_loss: 0.1319 - val_accuracy: 0.9777\n",
      "Epoch 55/150\n",
      "485/485 [==============================] - 1s 2ms/step - loss: 0.1283 - accuracy: 0.9801 - val_loss: 0.1797 - val_accuracy: 0.9572\n",
      "Epoch 56/150\n",
      "485/485 [==============================] - 1s 1ms/step - loss: 0.1288 - accuracy: 0.9801 - val_loss: 0.1253 - val_accuracy: 0.9810\n",
      "Epoch 57/150\n",
      "485/485 [==============================] - 1s 2ms/step - loss: 0.1248 - accuracy: 0.9814 - val_loss: 0.1341 - val_accuracy: 0.9814\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 58/150\n",
      "485/485 [==============================] - 1s 2ms/step - loss: 0.1330 - accuracy: 0.9783 - val_loss: 0.1583 - val_accuracy: 0.9740\n",
      "Epoch 59/150\n",
      "485/485 [==============================] - 1s 2ms/step - loss: 0.1199 - accuracy: 0.9833 - val_loss: 0.1182 - val_accuracy: 0.9857\n",
      "Epoch 60/150\n",
      "485/485 [==============================] - 1s 2ms/step - loss: 0.1294 - accuracy: 0.9779 - val_loss: 0.1741 - val_accuracy: 0.9627\n",
      "Epoch 61/150\n",
      "485/485 [==============================] - 1s 2ms/step - loss: 0.1215 - accuracy: 0.9819 - val_loss: 0.1166 - val_accuracy: 0.9832\n",
      "Epoch 62/150\n",
      "485/485 [==============================] - 1s 2ms/step - loss: 0.1243 - accuracy: 0.9814 - val_loss: 0.1719 - val_accuracy: 0.9583\n",
      "Epoch 63/150\n",
      "485/485 [==============================] - 1s 2ms/step - loss: 0.1287 - accuracy: 0.9790 - val_loss: 0.1714 - val_accuracy: 0.9649\n",
      "Epoch 64/150\n",
      "485/485 [==============================] - 1s 2ms/step - loss: 0.1214 - accuracy: 0.9814 - val_loss: 0.1226 - val_accuracy: 0.9810\n",
      "Epoch 65/150\n",
      "485/485 [==============================] - 1s 1ms/step - loss: 0.1201 - accuracy: 0.9815 - val_loss: 0.1323 - val_accuracy: 0.9755\n",
      "Epoch 66/150\n",
      "485/485 [==============================] - 1s 2ms/step - loss: 0.1218 - accuracy: 0.9809 - val_loss: 0.1393 - val_accuracy: 0.9777\n",
      "Epoch 67/150\n",
      "485/485 [==============================] - 1s 2ms/step - loss: 0.1208 - accuracy: 0.9812 - val_loss: 0.1724 - val_accuracy: 0.9660\n",
      "Epoch 68/150\n",
      "485/485 [==============================] - 1s 2ms/step - loss: 0.1331 - accuracy: 0.9768 - val_loss: 0.1225 - val_accuracy: 0.9821\n",
      "Epoch 69/150\n",
      "485/485 [==============================] - 1s 2ms/step - loss: 0.1186 - accuracy: 0.9828 - val_loss: 0.1624 - val_accuracy: 0.9649\n",
      "Epoch 70/150\n",
      "485/485 [==============================] - 1s 2ms/step - loss: 0.1164 - accuracy: 0.9828 - val_loss: 0.1184 - val_accuracy: 0.9825\n",
      "Epoch 71/150\n",
      "485/485 [==============================] - 1s 2ms/step - loss: 0.1195 - accuracy: 0.9815 - val_loss: 0.1209 - val_accuracy: 0.9814\n",
      "Epoch 72/150\n",
      "485/485 [==============================] - 1s 2ms/step - loss: 0.1194 - accuracy: 0.9807 - val_loss: 0.1812 - val_accuracy: 0.9591\n",
      "Epoch 73/150\n",
      "485/485 [==============================] - 1s 2ms/step - loss: 0.1191 - accuracy: 0.9811 - val_loss: 0.1100 - val_accuracy: 0.9843\n",
      "Epoch 74/150\n",
      "485/485 [==============================] - 1s 2ms/step - loss: 0.1195 - accuracy: 0.9809 - val_loss: 0.1110 - val_accuracy: 0.9825\n",
      "Epoch 75/150\n",
      "485/485 [==============================] - 1s 2ms/step - loss: 0.1152 - accuracy: 0.9826 - val_loss: 0.1087 - val_accuracy: 0.9832\n",
      "Epoch 76/150\n",
      "485/485 [==============================] - 1s 2ms/step - loss: 0.1228 - accuracy: 0.9793 - val_loss: 0.1122 - val_accuracy: 0.9825\n",
      "Epoch 77/150\n",
      "485/485 [==============================] - 1s 2ms/step - loss: 0.1187 - accuracy: 0.9814 - val_loss: 0.1407 - val_accuracy: 0.9744\n",
      "Epoch 78/150\n",
      "485/485 [==============================] - 1s 1ms/step - loss: 0.1122 - accuracy: 0.9837 - val_loss: 0.1091 - val_accuracy: 0.9832\n",
      "Epoch 79/150\n",
      "485/485 [==============================] - 1s 1ms/step - loss: 0.1212 - accuracy: 0.9798 - val_loss: 0.1121 - val_accuracy: 0.9825\n",
      "Epoch 80/150\n",
      "485/485 [==============================] - 1s 2ms/step - loss: 0.1179 - accuracy: 0.9815 - val_loss: 0.2668 - val_accuracy: 0.9167\n",
      "Epoch 81/150\n",
      "485/485 [==============================] - 1s 2ms/step - loss: 0.1204 - accuracy: 0.9797 - val_loss: 0.1157 - val_accuracy: 0.9825\n",
      "Epoch 82/150\n",
      "485/485 [==============================] - 1s 2ms/step - loss: 0.1180 - accuracy: 0.9813 - val_loss: 0.1693 - val_accuracy: 0.9561\n",
      "Epoch 83/150\n",
      "485/485 [==============================] - 1s 2ms/step - loss: 0.1110 - accuracy: 0.9843 - val_loss: 0.1110 - val_accuracy: 0.9825\n",
      "Epoch 84/150\n",
      "485/485 [==============================] - 1s 2ms/step - loss: 0.1187 - accuracy: 0.9793 - val_loss: 0.1089 - val_accuracy: 0.9825\n",
      "Epoch 85/150\n",
      "485/485 [==============================] - 1s 2ms/step - loss: 0.1186 - accuracy: 0.9804 - val_loss: 0.1313 - val_accuracy: 0.9748\n",
      "Epoch 86/150\n",
      "485/485 [==============================] - 1s 2ms/step - loss: 0.1196 - accuracy: 0.9799 - val_loss: 0.1211 - val_accuracy: 0.9803\n",
      "Epoch 87/150\n",
      "485/485 [==============================] - 1s 2ms/step - loss: 0.1052 - accuracy: 0.9860 - val_loss: 0.1899 - val_accuracy: 0.9459\n",
      "Epoch 88/150\n",
      "485/485 [==============================] - 1s 2ms/step - loss: 0.1204 - accuracy: 0.9794 - val_loss: 0.1201 - val_accuracy: 0.9825\n",
      "Epoch 89/150\n",
      "485/485 [==============================] - 1s 2ms/step - loss: 0.1133 - accuracy: 0.9832 - val_loss: 0.1773 - val_accuracy: 0.9539\n",
      "Epoch 90/150\n",
      "485/485 [==============================] - 1s 1ms/step - loss: 0.1216 - accuracy: 0.9799 - val_loss: 0.1419 - val_accuracy: 0.9722\n",
      "Epoch 91/150\n",
      "485/485 [==============================] - 1s 2ms/step - loss: 0.1132 - accuracy: 0.9823 - val_loss: 0.1563 - val_accuracy: 0.9664\n",
      "Epoch 92/150\n",
      "485/485 [==============================] - 1s 2ms/step - loss: 0.1147 - accuracy: 0.9823 - val_loss: 0.1300 - val_accuracy: 0.9784\n",
      "Epoch 93/150\n",
      "485/485 [==============================] - 1s 2ms/step - loss: 0.1119 - accuracy: 0.9829 - val_loss: 0.1272 - val_accuracy: 0.9814\n",
      "Epoch 94/150\n",
      "485/485 [==============================] - 1s 2ms/step - loss: 0.1097 - accuracy: 0.9832 - val_loss: 0.1363 - val_accuracy: 0.9740\n",
      "Epoch 95/150\n",
      "485/485 [==============================] - 1s 2ms/step - loss: 0.1170 - accuracy: 0.9795 - val_loss: 0.1249 - val_accuracy: 0.9806\n",
      "Epoch 96/150\n",
      "485/485 [==============================] - 1s 2ms/step - loss: 0.1089 - accuracy: 0.9841 - val_loss: 0.1398 - val_accuracy: 0.9730\n",
      "Epoch 97/150\n",
      "485/485 [==============================] - 1s 2ms/step - loss: 0.1083 - accuracy: 0.9839 - val_loss: 0.1307 - val_accuracy: 0.9689\n",
      "Epoch 98/150\n",
      "485/485 [==============================] - 1s 2ms/step - loss: 0.1153 - accuracy: 0.9814 - val_loss: 0.1412 - val_accuracy: 0.9689\n",
      "Epoch 99/150\n",
      "485/485 [==============================] - 1s 2ms/step - loss: 0.1140 - accuracy: 0.9814 - val_loss: 0.1138 - val_accuracy: 0.9806\n",
      "Epoch 100/150\n",
      "485/485 [==============================] - 1s 2ms/step - loss: 0.1048 - accuracy: 0.9845 - val_loss: 0.1226 - val_accuracy: 0.9784\n",
      "Epoch 101/150\n",
      "485/485 [==============================] - 1s 2ms/step - loss: 0.1077 - accuracy: 0.9837 - val_loss: 0.1183 - val_accuracy: 0.9806\n",
      "Epoch 102/150\n",
      "485/485 [==============================] - 1s 2ms/step - loss: 0.1059 - accuracy: 0.9845 - val_loss: 0.1057 - val_accuracy: 0.9825\n",
      "Epoch 103/150\n",
      "485/485 [==============================] - 1s 2ms/step - loss: 0.1100 - accuracy: 0.9823 - val_loss: 0.1036 - val_accuracy: 0.9825\n",
      "Epoch 104/150\n",
      "485/485 [==============================] - 1s 2ms/step - loss: 0.1156 - accuracy: 0.9802 - val_loss: 0.1028 - val_accuracy: 0.9825\n",
      "Epoch 105/150\n",
      "485/485 [==============================] - 1s 2ms/step - loss: 0.1153 - accuracy: 0.9788 - val_loss: 0.1209 - val_accuracy: 0.9821\n",
      "Epoch 106/150\n",
      "485/485 [==============================] - 1s 2ms/step - loss: 0.0982 - accuracy: 0.9878 - val_loss: 0.1532 - val_accuracy: 0.9675\n",
      "Epoch 107/150\n",
      "485/485 [==============================] - 1s 2ms/step - loss: 0.1119 - accuracy: 0.9826 - val_loss: 0.1980 - val_accuracy: 0.9470\n",
      "Epoch 108/150\n",
      "485/485 [==============================] - 1s 2ms/step - loss: 0.1131 - accuracy: 0.9819 - val_loss: 0.2005 - val_accuracy: 0.9404\n",
      "Epoch 109/150\n",
      "485/485 [==============================] - 1s 1ms/step - loss: 0.1122 - accuracy: 0.9822 - val_loss: 0.0994 - val_accuracy: 0.9890\n",
      "Epoch 110/150\n",
      "485/485 [==============================] - 1s 1ms/step - loss: 0.1153 - accuracy: 0.9805 - val_loss: 0.1209 - val_accuracy: 0.9781\n",
      "Epoch 111/150\n",
      "485/485 [==============================] - 1s 2ms/step - loss: 0.1180 - accuracy: 0.9801 - val_loss: 0.1537 - val_accuracy: 0.9616\n",
      "Epoch 112/150\n",
      "485/485 [==============================] - 1s 2ms/step - loss: 0.1063 - accuracy: 0.9841 - val_loss: 0.1003 - val_accuracy: 0.9876\n",
      "Epoch 113/150\n",
      "485/485 [==============================] - 1s 2ms/step - loss: 0.1031 - accuracy: 0.9846 - val_loss: 0.1033 - val_accuracy: 0.9843\n",
      "Epoch 114/150\n",
      "485/485 [==============================] - 1s 2ms/step - loss: 0.1169 - accuracy: 0.9802 - val_loss: 0.1004 - val_accuracy: 0.9861\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 115/150\n",
      "485/485 [==============================] - 1s 2ms/step - loss: 0.1114 - accuracy: 0.9804 - val_loss: 0.1159 - val_accuracy: 0.9821\n",
      "Epoch 116/150\n",
      "485/485 [==============================] - 1s 2ms/step - loss: 0.1046 - accuracy: 0.9845 - val_loss: 0.1137 - val_accuracy: 0.9803\n",
      "Epoch 117/150\n",
      "485/485 [==============================] - 1s 2ms/step - loss: 0.1092 - accuracy: 0.9817 - val_loss: 0.1174 - val_accuracy: 0.9773\n",
      "Epoch 118/150\n",
      "485/485 [==============================] - 1s 2ms/step - loss: 0.1065 - accuracy: 0.9829 - val_loss: 0.1315 - val_accuracy: 0.9715\n",
      "Epoch 119/150\n",
      "485/485 [==============================] - 1s 2ms/step - loss: 0.1045 - accuracy: 0.9839 - val_loss: 0.1286 - val_accuracy: 0.9722\n",
      "Epoch 120/150\n",
      "485/485 [==============================] - 1s 2ms/step - loss: 0.1138 - accuracy: 0.9801 - val_loss: 0.1382 - val_accuracy: 0.9766\n",
      "Epoch 121/150\n",
      "485/485 [==============================] - 1s 2ms/step - loss: 0.0999 - accuracy: 0.9858 - val_loss: 0.1038 - val_accuracy: 0.9854\n",
      "Epoch 122/150\n",
      "485/485 [==============================] - 1s 2ms/step - loss: 0.1142 - accuracy: 0.9800 - val_loss: 0.1329 - val_accuracy: 0.9773\n",
      "Epoch 123/150\n",
      "485/485 [==============================] - 1s 2ms/step - loss: 0.1019 - accuracy: 0.9853 - val_loss: 0.1048 - val_accuracy: 0.9832\n",
      "Epoch 124/150\n",
      "485/485 [==============================] - 1s 2ms/step - loss: 0.1062 - accuracy: 0.9835 - val_loss: 0.1056 - val_accuracy: 0.9821\n",
      "Epoch 125/150\n",
      "485/485 [==============================] - 1s 2ms/step - loss: 0.1093 - accuracy: 0.9818 - val_loss: 0.1311 - val_accuracy: 0.9733\n",
      "Epoch 126/150\n",
      "485/485 [==============================] - 1s 2ms/step - loss: 0.1119 - accuracy: 0.9812 - val_loss: 0.1299 - val_accuracy: 0.9751\n",
      "Epoch 127/150\n",
      "485/485 [==============================] - 1s 2ms/step - loss: 0.0993 - accuracy: 0.9866 - val_loss: 0.1078 - val_accuracy: 0.9843\n",
      "Epoch 128/150\n",
      "485/485 [==============================] - 1s 2ms/step - loss: 0.1117 - accuracy: 0.9804 - val_loss: 0.1156 - val_accuracy: 0.9825\n",
      "Epoch 129/150\n",
      "485/485 [==============================] - 1s 2ms/step - loss: 0.1073 - accuracy: 0.9823 - val_loss: 0.1238 - val_accuracy: 0.9770\n",
      "Epoch 130/150\n",
      "485/485 [==============================] - 1s 2ms/step - loss: 0.1042 - accuracy: 0.9839 - val_loss: 0.1134 - val_accuracy: 0.9806\n",
      "Epoch 131/150\n",
      "485/485 [==============================] - 1s 2ms/step - loss: 0.1038 - accuracy: 0.9841 - val_loss: 0.1064 - val_accuracy: 0.9832\n",
      "Epoch 132/150\n",
      "485/485 [==============================] - 1s 2ms/step - loss: 0.0996 - accuracy: 0.9858 - val_loss: 0.0933 - val_accuracy: 0.9890\n",
      "Epoch 133/150\n",
      "485/485 [==============================] - 1s 1ms/step - loss: 0.1037 - accuracy: 0.9832 - val_loss: 0.1120 - val_accuracy: 0.9814\n",
      "Epoch 134/150\n",
      "485/485 [==============================] - 1s 2ms/step - loss: 0.1073 - accuracy: 0.9836 - val_loss: 0.1038 - val_accuracy: 0.9828\n",
      "Epoch 135/150\n",
      "485/485 [==============================] - 1s 2ms/step - loss: 0.0998 - accuracy: 0.9850 - val_loss: 0.0946 - val_accuracy: 0.9890\n",
      "Epoch 136/150\n",
      "485/485 [==============================] - 1s 2ms/step - loss: 0.1049 - accuracy: 0.9834 - val_loss: 0.0980 - val_accuracy: 0.9846\n",
      "Epoch 137/150\n",
      "485/485 [==============================] - 1s 2ms/step - loss: 0.1021 - accuracy: 0.9845 - val_loss: 0.1105 - val_accuracy: 0.9821\n",
      "Epoch 138/150\n",
      "485/485 [==============================] - 1s 2ms/step - loss: 0.0925 - accuracy: 0.9880 - val_loss: 0.0913 - val_accuracy: 0.9890\n",
      "Epoch 139/150\n",
      "485/485 [==============================] - 1s 2ms/step - loss: 0.1195 - accuracy: 0.9783 - val_loss: 0.0974 - val_accuracy: 0.9861\n",
      "Epoch 140/150\n",
      "485/485 [==============================] - 1s 2ms/step - loss: 0.0893 - accuracy: 0.9890 - val_loss: 0.0899 - val_accuracy: 0.9890\n",
      "Epoch 141/150\n",
      "485/485 [==============================] - 1s 2ms/step - loss: 0.1099 - accuracy: 0.9810 - val_loss: 0.1086 - val_accuracy: 0.9846\n",
      "Epoch 142/150\n",
      "485/485 [==============================] - 1s 2ms/step - loss: 0.1071 - accuracy: 0.9816 - val_loss: 0.1184 - val_accuracy: 0.9817\n",
      "Epoch 143/150\n",
      "485/485 [==============================] - 1s 2ms/step - loss: 0.0920 - accuracy: 0.9879 - val_loss: 0.0945 - val_accuracy: 0.9890\n",
      "Epoch 144/150\n",
      "485/485 [==============================] - 1s 1ms/step - loss: 0.1045 - accuracy: 0.9829 - val_loss: 0.0911 - val_accuracy: 0.9890\n",
      "Epoch 145/150\n",
      "485/485 [==============================] - 1s 2ms/step - loss: 0.1029 - accuracy: 0.9834 - val_loss: 0.0905 - val_accuracy: 0.9890\n",
      "Epoch 146/150\n",
      "485/485 [==============================] - 1s 2ms/step - loss: 0.1030 - accuracy: 0.9832 - val_loss: 0.1749 - val_accuracy: 0.9605\n",
      "Epoch 147/150\n",
      "485/485 [==============================] - 1s 2ms/step - loss: 0.0996 - accuracy: 0.9846 - val_loss: 0.0914 - val_accuracy: 0.9861\n",
      "Epoch 148/150\n",
      "485/485 [==============================] - 1s 2ms/step - loss: 0.1083 - accuracy: 0.9824 - val_loss: 0.0902 - val_accuracy: 0.9890\n",
      "Epoch 149/150\n",
      "485/485 [==============================] - 1s 2ms/step - loss: 0.1042 - accuracy: 0.9829 - val_loss: 0.1669 - val_accuracy: 0.9609\n",
      "Epoch 150/150\n",
      "485/485 [==============================] - 1s 1ms/step - loss: 0.0935 - accuracy: 0.9867 - val_loss: 0.0869 - val_accuracy: 0.9890\n",
      "Accuracy for the prediction of hypertension:0.9907\n"
     ]
    }
   ],
   "source": [
    "#We use the sequential package from Keras to build customizable layers for the network. \n",
    "model = Sequential()\n",
    "model.add(Dense(11, input_dim=13, activation=\"relu\", kernel_regularizer=keras.regularizers.l2(0.1)))\n",
    "model.add(Dense(9, activation=\"relu\"))\n",
    "model.add(Dense(7, activation=\"relu\", kernel_regularizer=keras.regularizers.l2(0.1)))\n",
    "model.add(Dense(5, activation=\"relu\"))\n",
    "model.add(Dense(3, activation=\"relu\", kernel_regularizer=keras.regularizers.l2(0.1)))\n",
    "model.add(Dense(1, activation=tf.keras.activations.sigmoid))\n",
    "\n",
    "#Compiling the model previously built.\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "#Applying the model to fit the data\n",
    "history = model.fit(hd_X_train_scaled, hd_y_train, epochs=150, batch_size=32, verbose=1, validation_split = 0.15, shuffle = False)\n",
    "\n",
    "#Applying the model to the test dataset to predict outputs\n",
    "hd_y_predict = model.predict(hd_X_test_scaled)\n",
    "hd_y_predict = np.array(np.array(list(map(lambda x: 0 if x<0.5 else 1, hd_y_predict))))\n",
    "print(\"Accuracy for the prediction of hypertension:%.4f\" % accuracy_score(np.array(hd_y_test), np.array(hd_y_predict)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "3e7ccdde",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#plotting the learning curve to help to see if the model is overfitting\n",
    "\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'val'], loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "3ad183ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "760/760 [==============================] - 3s 2ms/step - loss: 0.9444 - accuracy: 0.6482 - val_loss: 0.6570 - val_accuracy: 0.6753\n",
      "Epoch 2/150\n",
      "760/760 [==============================] - 1s 2ms/step - loss: 0.6317 - accuracy: 0.6898 - val_loss: 0.6302 - val_accuracy: 0.6795\n",
      "Epoch 3/150\n",
      "760/760 [==============================] - 1s 2ms/step - loss: 0.6181 - accuracy: 0.6889 - val_loss: 0.6218 - val_accuracy: 0.6825\n",
      "Epoch 4/150\n",
      "760/760 [==============================] - 1s 2ms/step - loss: 0.6119 - accuracy: 0.6901 - val_loss: 0.6173 - val_accuracy: 0.6828\n",
      "Epoch 5/150\n",
      "760/760 [==============================] - 1s 2ms/step - loss: 0.6082 - accuracy: 0.6907 - val_loss: 0.6142 - val_accuracy: 0.6837\n",
      "Epoch 6/150\n",
      "760/760 [==============================] - 2s 3ms/step - loss: 0.6050 - accuracy: 0.6919 - val_loss: 0.6115 - val_accuracy: 0.6841\n",
      "Epoch 7/150\n",
      "760/760 [==============================] - 2s 3ms/step - loss: 0.6021 - accuracy: 0.6930 - val_loss: 0.6090 - val_accuracy: 0.6886\n",
      "Epoch 8/150\n",
      "760/760 [==============================] - 2s 3ms/step - loss: 0.5990 - accuracy: 0.6964 - val_loss: 0.6060 - val_accuracy: 0.6907\n",
      "Epoch 9/150\n",
      "760/760 [==============================] - 2s 3ms/step - loss: 0.5958 - accuracy: 0.6989 - val_loss: 0.6033 - val_accuracy: 0.6911\n",
      "Epoch 10/150\n",
      "760/760 [==============================] - 2s 2ms/step - loss: 0.5935 - accuracy: 0.7006 - val_loss: 0.6013 - val_accuracy: 0.6916\n",
      "Epoch 11/150\n",
      "760/760 [==============================] - 2s 2ms/step - loss: 0.5916 - accuracy: 0.7014 - val_loss: 0.6001 - val_accuracy: 0.6921\n",
      "Epoch 12/150\n",
      "760/760 [==============================] - 1s 2ms/step - loss: 0.5903 - accuracy: 0.7017 - val_loss: 0.5986 - val_accuracy: 0.6958\n",
      "Epoch 13/150\n",
      "760/760 [==============================] - 1s 1ms/step - loss: 0.5891 - accuracy: 0.7018 - val_loss: 0.5979 - val_accuracy: 0.6916\n",
      "Epoch 14/150\n",
      "760/760 [==============================] - 1s 1ms/step - loss: 0.5882 - accuracy: 0.7021 - val_loss: 0.5968 - val_accuracy: 0.6918\n",
      "Epoch 15/150\n",
      "760/760 [==============================] - 1s 2ms/step - loss: 0.5864 - accuracy: 0.7040 - val_loss: 0.5948 - val_accuracy: 0.7007\n",
      "Epoch 16/150\n",
      "760/760 [==============================] - 1s 1ms/step - loss: 0.5849 - accuracy: 0.7055 - val_loss: 0.5933 - val_accuracy: 0.7021\n",
      "Epoch 17/150\n",
      "760/760 [==============================] - 1s 1ms/step - loss: 0.5835 - accuracy: 0.7060 - val_loss: 0.5931 - val_accuracy: 0.6998\n",
      "Epoch 18/150\n",
      "760/760 [==============================] - 1s 2ms/step - loss: 0.5826 - accuracy: 0.7062 - val_loss: 0.5924 - val_accuracy: 0.6993\n",
      "Epoch 19/150\n",
      "760/760 [==============================] - 1s 1ms/step - loss: 0.5819 - accuracy: 0.7068 - val_loss: 0.5918 - val_accuracy: 0.7012\n",
      "Epoch 20/150\n",
      "760/760 [==============================] - 1s 1ms/step - loss: 0.5812 - accuracy: 0.7079 - val_loss: 0.5912 - val_accuracy: 0.7007\n",
      "Epoch 21/150\n",
      "760/760 [==============================] - 1s 2ms/step - loss: 0.5805 - accuracy: 0.7076 - val_loss: 0.5908 - val_accuracy: 0.7000\n",
      "Epoch 22/150\n",
      "760/760 [==============================] - 2s 2ms/step - loss: 0.5799 - accuracy: 0.7077 - val_loss: 0.5902 - val_accuracy: 0.7012\n",
      "Epoch 23/150\n",
      "760/760 [==============================] - 2s 2ms/step - loss: 0.5792 - accuracy: 0.7094 - val_loss: 0.5898 - val_accuracy: 0.7019\n",
      "Epoch 24/150\n",
      "760/760 [==============================] - 1s 2ms/step - loss: 0.5784 - accuracy: 0.7092 - val_loss: 0.5889 - val_accuracy: 0.6998\n",
      "Epoch 25/150\n",
      "760/760 [==============================] - 1s 2ms/step - loss: 0.5776 - accuracy: 0.7103 - val_loss: 0.5881 - val_accuracy: 0.6984\n",
      "Epoch 26/150\n",
      "760/760 [==============================] - 1s 2ms/step - loss: 0.5768 - accuracy: 0.7112 - val_loss: 0.5865 - val_accuracy: 0.7019\n",
      "Epoch 27/150\n",
      "760/760 [==============================] - 2s 3ms/step - loss: 0.5760 - accuracy: 0.7114 - val_loss: 0.5864 - val_accuracy: 0.6998\n",
      "Epoch 28/150\n",
      "760/760 [==============================] - 2s 2ms/step - loss: 0.5751 - accuracy: 0.7127 - val_loss: 0.5856 - val_accuracy: 0.7026\n",
      "Epoch 29/150\n",
      "760/760 [==============================] - 1s 2ms/step - loss: 0.5742 - accuracy: 0.7137 - val_loss: 0.5848 - val_accuracy: 0.6995\n",
      "Epoch 30/150\n",
      "760/760 [==============================] - 1s 2ms/step - loss: 0.5735 - accuracy: 0.7142 - val_loss: 0.5830 - val_accuracy: 0.7021\n",
      "Epoch 31/150\n",
      "760/760 [==============================] - 2s 3ms/step - loss: 0.5722 - accuracy: 0.7160 - val_loss: 0.5824 - val_accuracy: 0.7014\n",
      "Epoch 32/150\n",
      "760/760 [==============================] - 2s 2ms/step - loss: 0.5713 - accuracy: 0.7173 - val_loss: 0.5814 - val_accuracy: 0.7000\n",
      "Epoch 33/150\n",
      "760/760 [==============================] - 1s 2ms/step - loss: 0.5691 - accuracy: 0.7202 - val_loss: 0.5788 - val_accuracy: 0.7023\n",
      "Epoch 34/150\n",
      "760/760 [==============================] - 2s 2ms/step - loss: 0.5677 - accuracy: 0.7221 - val_loss: 0.5773 - val_accuracy: 0.7026\n",
      "Epoch 35/150\n",
      "760/760 [==============================] - 1s 2ms/step - loss: 0.5664 - accuracy: 0.7222 - val_loss: 0.5760 - val_accuracy: 0.7061\n",
      "Epoch 36/150\n",
      "760/760 [==============================] - 2s 3ms/step - loss: 0.5652 - accuracy: 0.7231 - val_loss: 0.5746 - val_accuracy: 0.7068\n",
      "Epoch 37/150\n",
      "760/760 [==============================] - 2s 2ms/step - loss: 0.5642 - accuracy: 0.7237 - val_loss: 0.5729 - val_accuracy: 0.7093\n",
      "Epoch 38/150\n",
      "760/760 [==============================] - 1s 2ms/step - loss: 0.5632 - accuracy: 0.7244 - val_loss: 0.5728 - val_accuracy: 0.7093\n",
      "Epoch 39/150\n",
      "760/760 [==============================] - 1s 2ms/step - loss: 0.5623 - accuracy: 0.7248 - val_loss: 0.5713 - val_accuracy: 0.7089\n",
      "Epoch 40/150\n",
      "760/760 [==============================] - 1s 2ms/step - loss: 0.5612 - accuracy: 0.7249 - val_loss: 0.5704 - val_accuracy: 0.7105\n",
      "Epoch 41/150\n",
      "760/760 [==============================] - 1s 1ms/step - loss: 0.5602 - accuracy: 0.7252 - val_loss: 0.5687 - val_accuracy: 0.7117\n",
      "Epoch 42/150\n",
      "760/760 [==============================] - 1s 1ms/step - loss: 0.5595 - accuracy: 0.7254 - val_loss: 0.5679 - val_accuracy: 0.7124\n",
      "Epoch 43/150\n",
      "760/760 [==============================] - 1s 1ms/step - loss: 0.5585 - accuracy: 0.7261 - val_loss: 0.5677 - val_accuracy: 0.7117\n",
      "Epoch 44/150\n",
      "760/760 [==============================] - 1s 1ms/step - loss: 0.5577 - accuracy: 0.7252 - val_loss: 0.5653 - val_accuracy: 0.7135\n",
      "Epoch 45/150\n",
      "760/760 [==============================] - 1s 2ms/step - loss: 0.5568 - accuracy: 0.7261 - val_loss: 0.5642 - val_accuracy: 0.7131\n",
      "Epoch 46/150\n",
      "760/760 [==============================] - 2s 2ms/step - loss: 0.5558 - accuracy: 0.7269 - val_loss: 0.5631 - val_accuracy: 0.7124\n",
      "Epoch 47/150\n",
      "760/760 [==============================] - 2s 2ms/step - loss: 0.5549 - accuracy: 0.7277 - val_loss: 0.5609 - val_accuracy: 0.7142\n",
      "Epoch 48/150\n",
      "760/760 [==============================] - 1s 2ms/step - loss: 0.5538 - accuracy: 0.7282 - val_loss: 0.5587 - val_accuracy: 0.7138\n",
      "Epoch 49/150\n",
      "760/760 [==============================] - 1s 2ms/step - loss: 0.5514 - accuracy: 0.7293 - val_loss: 0.5555 - val_accuracy: 0.7182\n",
      "Epoch 50/150\n",
      "760/760 [==============================] - 1s 2ms/step - loss: 0.5495 - accuracy: 0.7311 - val_loss: 0.5547 - val_accuracy: 0.7198\n",
      "Epoch 51/150\n",
      "760/760 [==============================] - 2s 2ms/step - loss: 0.5485 - accuracy: 0.7320 - val_loss: 0.5527 - val_accuracy: 0.7205\n",
      "Epoch 52/150\n",
      "760/760 [==============================] - 1s 2ms/step - loss: 0.5476 - accuracy: 0.7320 - val_loss: 0.5525 - val_accuracy: 0.7210\n",
      "Epoch 53/150\n",
      "760/760 [==============================] - 1s 2ms/step - loss: 0.5471 - accuracy: 0.7329 - val_loss: 0.5515 - val_accuracy: 0.7214\n",
      "Epoch 54/150\n",
      "760/760 [==============================] - 1s 2ms/step - loss: 0.5464 - accuracy: 0.7318 - val_loss: 0.5504 - val_accuracy: 0.7200\n",
      "Epoch 55/150\n",
      "760/760 [==============================] - 2s 2ms/step - loss: 0.5455 - accuracy: 0.7330 - val_loss: 0.5493 - val_accuracy: 0.7214\n",
      "Epoch 56/150\n",
      "760/760 [==============================] - 1s 1ms/step - loss: 0.5451 - accuracy: 0.7333 - val_loss: 0.5475 - val_accuracy: 0.7235\n",
      "Epoch 57/150\n",
      "760/760 [==============================] - 1s 2ms/step - loss: 0.5443 - accuracy: 0.7330 - val_loss: 0.5468 - val_accuracy: 0.7247\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 58/150\n",
      "760/760 [==============================] - 1s 2ms/step - loss: 0.5438 - accuracy: 0.7344 - val_loss: 0.5456 - val_accuracy: 0.7266\n",
      "Epoch 59/150\n",
      "760/760 [==============================] - 2s 2ms/step - loss: 0.5433 - accuracy: 0.7341 - val_loss: 0.5460 - val_accuracy: 0.7235\n",
      "Epoch 60/150\n",
      "760/760 [==============================] - 1s 2ms/step - loss: 0.5428 - accuracy: 0.7339 - val_loss: 0.5451 - val_accuracy: 0.7259\n",
      "Epoch 61/150\n",
      "760/760 [==============================] - 2s 3ms/step - loss: 0.5421 - accuracy: 0.7338 - val_loss: 0.5435 - val_accuracy: 0.7256\n",
      "Epoch 62/150\n",
      "760/760 [==============================] - 2s 2ms/step - loss: 0.5417 - accuracy: 0.7347 - val_loss: 0.5442 - val_accuracy: 0.7252\n",
      "Epoch 63/150\n",
      "760/760 [==============================] - 1s 2ms/step - loss: 0.5412 - accuracy: 0.7338 - val_loss: 0.5432 - val_accuracy: 0.7273\n",
      "Epoch 64/150\n",
      "760/760 [==============================] - 1s 2ms/step - loss: 0.5406 - accuracy: 0.7344 - val_loss: 0.5433 - val_accuracy: 0.7270\n",
      "Epoch 65/150\n",
      "760/760 [==============================] - 1s 2ms/step - loss: 0.5403 - accuracy: 0.7351 - val_loss: 0.5428 - val_accuracy: 0.7273\n",
      "Epoch 66/150\n",
      "760/760 [==============================] - 1s 2ms/step - loss: 0.5399 - accuracy: 0.7358 - val_loss: 0.5423 - val_accuracy: 0.7287\n",
      "Epoch 67/150\n",
      "760/760 [==============================] - 1s 2ms/step - loss: 0.5394 - accuracy: 0.7356 - val_loss: 0.5431 - val_accuracy: 0.7305\n",
      "Epoch 68/150\n",
      "760/760 [==============================] - 1s 2ms/step - loss: 0.5389 - accuracy: 0.7370 - val_loss: 0.5413 - val_accuracy: 0.7296\n",
      "Epoch 69/150\n",
      "760/760 [==============================] - 1s 2ms/step - loss: 0.5380 - accuracy: 0.7384 - val_loss: 0.5394 - val_accuracy: 0.7343\n",
      "Epoch 70/150\n",
      "760/760 [==============================] - 1s 2ms/step - loss: 0.5372 - accuracy: 0.7406 - val_loss: 0.5368 - val_accuracy: 0.7301\n",
      "Epoch 71/150\n",
      "760/760 [==============================] - 1s 1ms/step - loss: 0.5363 - accuracy: 0.7416 - val_loss: 0.5350 - val_accuracy: 0.7359\n",
      "Epoch 72/150\n",
      "760/760 [==============================] - 1s 1ms/step - loss: 0.5360 - accuracy: 0.7414 - val_loss: 0.5348 - val_accuracy: 0.7368\n",
      "Epoch 73/150\n",
      "760/760 [==============================] - 1s 2ms/step - loss: 0.5353 - accuracy: 0.7413 - val_loss: 0.5336 - val_accuracy: 0.7368\n",
      "Epoch 74/150\n",
      "760/760 [==============================] - 1s 2ms/step - loss: 0.5342 - accuracy: 0.7423 - val_loss: 0.5338 - val_accuracy: 0.7350\n",
      "Epoch 75/150\n",
      "760/760 [==============================] - 1s 2ms/step - loss: 0.5339 - accuracy: 0.7422 - val_loss: 0.5334 - val_accuracy: 0.7347\n",
      "Epoch 76/150\n",
      "760/760 [==============================] - 1s 2ms/step - loss: 0.5334 - accuracy: 0.7436 - val_loss: 0.5319 - val_accuracy: 0.7406\n",
      "Epoch 77/150\n",
      "760/760 [==============================] - 3s 3ms/step - loss: 0.5332 - accuracy: 0.7421 - val_loss: 0.5312 - val_accuracy: 0.7389\n",
      "Epoch 78/150\n",
      "760/760 [==============================] - 2s 3ms/step - loss: 0.5328 - accuracy: 0.7429 - val_loss: 0.5316 - val_accuracy: 0.7385\n",
      "Epoch 79/150\n",
      "760/760 [==============================] - 2s 2ms/step - loss: 0.5322 - accuracy: 0.7432 - val_loss: 0.5310 - val_accuracy: 0.7427\n",
      "Epoch 80/150\n",
      "760/760 [==============================] - 1s 2ms/step - loss: 0.5320 - accuracy: 0.7432 - val_loss: 0.5296 - val_accuracy: 0.7394\n",
      "Epoch 81/150\n",
      "760/760 [==============================] - 1s 2ms/step - loss: 0.5313 - accuracy: 0.7434 - val_loss: 0.5310 - val_accuracy: 0.7396\n",
      "Epoch 82/150\n",
      "760/760 [==============================] - 1s 1ms/step - loss: 0.5310 - accuracy: 0.7442 - val_loss: 0.5287 - val_accuracy: 0.7394\n",
      "Epoch 83/150\n",
      "760/760 [==============================] - 1s 1ms/step - loss: 0.5308 - accuracy: 0.7435 - val_loss: 0.5296 - val_accuracy: 0.7396\n",
      "Epoch 84/150\n",
      "760/760 [==============================] - 1s 2ms/step - loss: 0.5305 - accuracy: 0.7432 - val_loss: 0.5283 - val_accuracy: 0.7403\n",
      "Epoch 85/150\n",
      "760/760 [==============================] - 1s 2ms/step - loss: 0.5302 - accuracy: 0.7428 - val_loss: 0.5285 - val_accuracy: 0.7401\n",
      "Epoch 86/150\n",
      "760/760 [==============================] - 1s 1ms/step - loss: 0.5297 - accuracy: 0.7426 - val_loss: 0.5279 - val_accuracy: 0.7408\n",
      "Epoch 87/150\n",
      "760/760 [==============================] - 1s 1ms/step - loss: 0.5291 - accuracy: 0.7443 - val_loss: 0.5272 - val_accuracy: 0.7417\n",
      "Epoch 88/150\n",
      "760/760 [==============================] - 1s 1ms/step - loss: 0.5287 - accuracy: 0.7444 - val_loss: 0.5283 - val_accuracy: 0.7401\n",
      "Epoch 89/150\n",
      "760/760 [==============================] - 1s 1ms/step - loss: 0.5284 - accuracy: 0.7449 - val_loss: 0.5272 - val_accuracy: 0.7399\n",
      "Epoch 90/150\n",
      "760/760 [==============================] - 1s 2ms/step - loss: 0.5280 - accuracy: 0.7445 - val_loss: 0.5279 - val_accuracy: 0.7352\n",
      "Epoch 91/150\n",
      "760/760 [==============================] - 1s 2ms/step - loss: 0.5277 - accuracy: 0.7446 - val_loss: 0.5265 - val_accuracy: 0.7399\n",
      "Epoch 92/150\n",
      "760/760 [==============================] - 1s 1ms/step - loss: 0.5275 - accuracy: 0.7438 - val_loss: 0.5269 - val_accuracy: 0.7333\n",
      "Epoch 93/150\n",
      "760/760 [==============================] - 1s 2ms/step - loss: 0.5273 - accuracy: 0.7437 - val_loss: 0.5259 - val_accuracy: 0.7417\n",
      "Epoch 94/150\n",
      "760/760 [==============================] - 1s 2ms/step - loss: 0.5269 - accuracy: 0.7448 - val_loss: 0.5265 - val_accuracy: 0.7410\n",
      "Epoch 95/150\n",
      "760/760 [==============================] - 1s 2ms/step - loss: 0.5267 - accuracy: 0.7443 - val_loss: 0.5254 - val_accuracy: 0.7415\n",
      "Epoch 96/150\n",
      "760/760 [==============================] - 1s 2ms/step - loss: 0.5260 - accuracy: 0.7446 - val_loss: 0.5252 - val_accuracy: 0.7403\n",
      "Epoch 97/150\n",
      "760/760 [==============================] - 1s 2ms/step - loss: 0.5256 - accuracy: 0.7456 - val_loss: 0.5235 - val_accuracy: 0.7424\n",
      "Epoch 98/150\n",
      "760/760 [==============================] - 1s 2ms/step - loss: 0.5255 - accuracy: 0.7464 - val_loss: 0.5244 - val_accuracy: 0.7438\n",
      "Epoch 99/150\n",
      "760/760 [==============================] - 1s 1ms/step - loss: 0.5252 - accuracy: 0.7468 - val_loss: 0.5246 - val_accuracy: 0.7392\n",
      "Epoch 100/150\n",
      "760/760 [==============================] - 1s 1ms/step - loss: 0.5252 - accuracy: 0.7467 - val_loss: 0.5236 - val_accuracy: 0.7422\n",
      "Epoch 101/150\n",
      "760/760 [==============================] - 1s 1ms/step - loss: 0.5250 - accuracy: 0.7468 - val_loss: 0.5237 - val_accuracy: 0.7403\n",
      "Epoch 102/150\n",
      "760/760 [==============================] - 1s 1ms/step - loss: 0.5247 - accuracy: 0.7477 - val_loss: 0.5227 - val_accuracy: 0.7427\n",
      "Epoch 103/150\n",
      "760/760 [==============================] - 1s 2ms/step - loss: 0.5244 - accuracy: 0.7482 - val_loss: 0.5221 - val_accuracy: 0.7424\n",
      "Epoch 104/150\n",
      "760/760 [==============================] - 1s 1ms/step - loss: 0.5244 - accuracy: 0.7467 - val_loss: 0.5224 - val_accuracy: 0.7422\n",
      "Epoch 105/150\n",
      "760/760 [==============================] - 1s 2ms/step - loss: 0.5238 - accuracy: 0.7488 - val_loss: 0.5215 - val_accuracy: 0.7441\n",
      "Epoch 106/150\n",
      "760/760 [==============================] - 1s 2ms/step - loss: 0.5235 - accuracy: 0.7488 - val_loss: 0.5207 - val_accuracy: 0.7457\n",
      "Epoch 107/150\n",
      "760/760 [==============================] - 1s 1ms/step - loss: 0.5233 - accuracy: 0.7479 - val_loss: 0.5207 - val_accuracy: 0.7438\n",
      "Epoch 108/150\n",
      "760/760 [==============================] - 1s 2ms/step - loss: 0.5224 - accuracy: 0.7498 - val_loss: 0.5184 - val_accuracy: 0.7450\n",
      "Epoch 109/150\n",
      "760/760 [==============================] - 1s 1ms/step - loss: 0.5218 - accuracy: 0.7511 - val_loss: 0.5176 - val_accuracy: 0.7497\n",
      "Epoch 110/150\n",
      "760/760 [==============================] - 1s 2ms/step - loss: 0.5207 - accuracy: 0.7516 - val_loss: 0.5189 - val_accuracy: 0.7464\n",
      "Epoch 111/150\n",
      "760/760 [==============================] - 1s 1ms/step - loss: 0.5205 - accuracy: 0.7513 - val_loss: 0.5170 - val_accuracy: 0.7476\n",
      "Epoch 112/150\n",
      "760/760 [==============================] - 1s 1ms/step - loss: 0.5198 - accuracy: 0.7523 - val_loss: 0.5170 - val_accuracy: 0.7513\n",
      "Epoch 113/150\n",
      "760/760 [==============================] - 1s 2ms/step - loss: 0.5191 - accuracy: 0.7523 - val_loss: 0.5174 - val_accuracy: 0.7517\n",
      "Epoch 114/150\n",
      "760/760 [==============================] - 1s 1ms/step - loss: 0.5188 - accuracy: 0.7508 - val_loss: 0.5197 - val_accuracy: 0.7529\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 115/150\n",
      "760/760 [==============================] - 1s 2ms/step - loss: 0.5182 - accuracy: 0.7516 - val_loss: 0.5205 - val_accuracy: 0.7483\n",
      "Epoch 116/150\n",
      "760/760 [==============================] - 1s 1ms/step - loss: 0.5175 - accuracy: 0.7540 - val_loss: 0.5207 - val_accuracy: 0.7536\n",
      "Epoch 117/150\n",
      "760/760 [==============================] - 1s 1ms/step - loss: 0.5176 - accuracy: 0.7541 - val_loss: 0.5194 - val_accuracy: 0.7562\n",
      "Epoch 118/150\n",
      "760/760 [==============================] - 1s 2ms/step - loss: 0.5167 - accuracy: 0.7546 - val_loss: 0.5187 - val_accuracy: 0.7527\n",
      "Epoch 119/150\n",
      "760/760 [==============================] - 1s 2ms/step - loss: 0.5162 - accuracy: 0.7553 - val_loss: 0.5171 - val_accuracy: 0.7529\n",
      "Epoch 120/150\n",
      "760/760 [==============================] - 1s 1ms/step - loss: 0.5156 - accuracy: 0.7560 - val_loss: 0.5172 - val_accuracy: 0.7529\n",
      "Epoch 121/150\n",
      "760/760 [==============================] - 1s 1ms/step - loss: 0.5154 - accuracy: 0.7548 - val_loss: 0.5151 - val_accuracy: 0.7576\n",
      "Epoch 122/150\n",
      "760/760 [==============================] - 1s 1ms/step - loss: 0.5149 - accuracy: 0.7570 - val_loss: 0.5159 - val_accuracy: 0.7543\n",
      "Epoch 123/150\n",
      "760/760 [==============================] - 1s 1ms/step - loss: 0.5145 - accuracy: 0.7564 - val_loss: 0.5163 - val_accuracy: 0.7566\n",
      "Epoch 124/150\n",
      "760/760 [==============================] - 1s 1ms/step - loss: 0.5145 - accuracy: 0.7553 - val_loss: 0.5160 - val_accuracy: 0.7569\n",
      "Epoch 125/150\n",
      "760/760 [==============================] - 1s 1ms/step - loss: 0.5139 - accuracy: 0.7573 - val_loss: 0.5158 - val_accuracy: 0.7566\n",
      "Epoch 126/150\n",
      "760/760 [==============================] - 1s 2ms/step - loss: 0.5138 - accuracy: 0.7557 - val_loss: 0.5140 - val_accuracy: 0.7594\n",
      "Epoch 127/150\n",
      "760/760 [==============================] - 1s 2ms/step - loss: 0.5135 - accuracy: 0.7577 - val_loss: 0.5154 - val_accuracy: 0.7578\n",
      "Epoch 128/150\n",
      "760/760 [==============================] - 1s 2ms/step - loss: 0.5135 - accuracy: 0.7565 - val_loss: 0.5129 - val_accuracy: 0.7594\n",
      "Epoch 129/150\n",
      "760/760 [==============================] - 1s 1ms/step - loss: 0.5131 - accuracy: 0.7575 - val_loss: 0.5117 - val_accuracy: 0.7552\n",
      "Epoch 130/150\n",
      "760/760 [==============================] - 1s 1ms/step - loss: 0.5131 - accuracy: 0.7578 - val_loss: 0.5119 - val_accuracy: 0.7578\n",
      "Epoch 131/150\n",
      "760/760 [==============================] - 2s 3ms/step - loss: 0.5125 - accuracy: 0.7574 - val_loss: 0.5113 - val_accuracy: 0.7576\n",
      "Epoch 132/150\n",
      "760/760 [==============================] - 2s 2ms/step - loss: 0.5129 - accuracy: 0.7565 - val_loss: 0.5108 - val_accuracy: 0.7583\n",
      "Epoch 133/150\n",
      "760/760 [==============================] - 1s 2ms/step - loss: 0.5123 - accuracy: 0.7584 - val_loss: 0.5085 - val_accuracy: 0.7592\n",
      "Epoch 134/150\n",
      "760/760 [==============================] - 1s 1ms/step - loss: 0.5115 - accuracy: 0.7581 - val_loss: 0.5092 - val_accuracy: 0.7550\n",
      "Epoch 135/150\n",
      "760/760 [==============================] - 1s 2ms/step - loss: 0.5111 - accuracy: 0.7588 - val_loss: 0.5055 - val_accuracy: 0.7611\n",
      "Epoch 136/150\n",
      "760/760 [==============================] - 1s 1ms/step - loss: 0.5109 - accuracy: 0.7589 - val_loss: 0.5058 - val_accuracy: 0.7650\n",
      "Epoch 137/150\n",
      "760/760 [==============================] - 1s 1ms/step - loss: 0.5104 - accuracy: 0.7605 - val_loss: 0.5063 - val_accuracy: 0.7611\n",
      "Epoch 138/150\n",
      "760/760 [==============================] - 1s 1ms/step - loss: 0.5098 - accuracy: 0.7593 - val_loss: 0.5050 - val_accuracy: 0.7634\n",
      "Epoch 139/150\n",
      "760/760 [==============================] - 1s 2ms/step - loss: 0.5098 - accuracy: 0.7595 - val_loss: 0.5074 - val_accuracy: 0.7597\n",
      "Epoch 140/150\n",
      "760/760 [==============================] - 2s 2ms/step - loss: 0.5090 - accuracy: 0.7605 - val_loss: 0.5073 - val_accuracy: 0.7615\n",
      "Epoch 141/150\n",
      "760/760 [==============================] - 1s 2ms/step - loss: 0.5090 - accuracy: 0.7601 - val_loss: 0.5047 - val_accuracy: 0.7674\n",
      "Epoch 142/150\n",
      "760/760 [==============================] - 2s 2ms/step - loss: 0.5088 - accuracy: 0.7603 - val_loss: 0.5041 - val_accuracy: 0.7643\n",
      "Epoch 143/150\n",
      "760/760 [==============================] - 2s 3ms/step - loss: 0.5087 - accuracy: 0.7602 - val_loss: 0.5052 - val_accuracy: 0.7641\n",
      "Epoch 144/150\n",
      "760/760 [==============================] - 1s 2ms/step - loss: 0.5086 - accuracy: 0.7604 - val_loss: 0.5050 - val_accuracy: 0.7601\n",
      "Epoch 145/150\n",
      "760/760 [==============================] - 2s 2ms/step - loss: 0.5082 - accuracy: 0.7616 - val_loss: 0.5044 - val_accuracy: 0.7611\n",
      "Epoch 146/150\n",
      "760/760 [==============================] - 2s 3ms/step - loss: 0.5082 - accuracy: 0.7621 - val_loss: 0.5050 - val_accuracy: 0.7615\n",
      "Epoch 147/150\n",
      "760/760 [==============================] - 2s 3ms/step - loss: 0.5077 - accuracy: 0.7611 - val_loss: 0.5045 - val_accuracy: 0.7618\n",
      "Epoch 148/150\n",
      "760/760 [==============================] - 2s 3ms/step - loss: 0.5068 - accuracy: 0.7615 - val_loss: 0.5047 - val_accuracy: 0.7615\n",
      "Epoch 149/150\n",
      "760/760 [==============================] - 2s 3ms/step - loss: 0.5064 - accuracy: 0.7619 - val_loss: 0.5014 - val_accuracy: 0.7625\n",
      "Epoch 150/150\n",
      "760/760 [==============================] - 2s 3ms/step - loss: 0.5060 - accuracy: 0.7618 - val_loss: 0.5034 - val_accuracy: 0.7615\n",
      "Accuracy for the prediction of stroke:0.7655\n"
     ]
    }
   ],
   "source": [
    "#We use the sequential package from Keras to build customizable layers for the network. \n",
    "model = Sequential()\n",
    "model.add(Dense(8, input_dim=10, activation=\"relu\", kernel_regularizer=keras.regularizers.l2(0.1)))\n",
    "model.add(Dense(6, activation=\"relu\"))\n",
    "model.add(Dense(4, activation=\"relu\", kernel_regularizer=keras.regularizers.l2(0.1)))\n",
    "model.add(Dense(2, activation=\"relu\"))\n",
    "#model.add(Dense(2, activation=\"relu\", kernel_regularizer=keras.regularizers.l2(0.1)))\n",
    "model.add(Dense(1, activation=tf.keras.activations.sigmoid))\n",
    "\n",
    "#Compiling the model previously built.\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "#Applying the model to fit the data\n",
    "history = model.fit(sd_X_train_scaled, sd_y_train, epochs=150, batch_size=32, verbose=1, validation_split = 0.15, shuffle = False)\n",
    "\n",
    "#Applying the model to the test dataset to predict outputs\n",
    "sd_y_predict = model.predict(sd_X_test_scaled)\n",
    "sd_y_predict = np.array(np.array(list(map(lambda x: 0 if x<0.5 else 1, sd_y_predict))))\n",
    "print(\"Accuracy for the prediction of stroke:%.4f\" % accuracy_score(np.array(sd_y_test), np.array(sd_y_predict)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "9ebbe580",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#plotting the learning curve to help to see if the model is overfitting\n",
    "\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'val'], loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "377d8f3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Accuracy for diabetes: 0.7261\n",
      "Random Forest Accuracy for hypertension: 1.0000\n",
      "Random Forest Accuracy for stroke: 0.9972\n",
      "Fitting 5 folds for each of 40 candidates, totalling 200 fits\n",
      "Best RF parameters for diabetes:  {'n_estimators': 150, 'min_samples_split': 14, 'min_samples_leaf': 6, 'max_features': 'auto', 'max_depth': 120, 'bootstrap': True}  \n",
      "\n",
      "Fitting 5 folds for each of 40 candidates, totalling 200 fits\n",
      "Best RF parameters for hypertension:  {'n_estimators': 50, 'min_samples_split': 14, 'min_samples_leaf': 1, 'max_features': 'sqrt', 'max_depth': 40, 'bootstrap': True}  \n",
      "\n",
      "Fitting 5 folds for each of 40 candidates, totalling 200 fits\n",
      "Best RF parameters for stroke:  {'n_estimators': 200, 'min_samples_split': 6, 'min_samples_leaf': 1, 'max_features': 'auto', 'max_depth': 100, 'bootstrap': False}  \n",
      "\n"
     ]
    }
   ],
   "source": [
    "#=============================\n",
    "#START OF RANDOM FOREST TESTING\n",
    "#=============================\n",
    "\n",
    "#setting variable parameters of the random forest to be tested later during the optimization of\n",
    "#the parameters\n",
    "\n",
    "n_estimators = [5, 20, 50, 100, 150, 200]\n",
    "max_features = ['auto', 'sqrt']\n",
    "max_depth = [int(x) for x in np.linspace(10, 120, num = 12)]\n",
    "min_samples_split = [2, 6, 10, 14] \n",
    "min_samples_leaf = [1, 3, 4, 6, 9] \n",
    "bootstrap = [True, False]\n",
    "\n",
    "grid = {'n_estimators': n_estimators,\n",
    "'max_features': max_features,\n",
    "'max_depth': max_depth,\n",
    "'min_samples_split': min_samples_split,\n",
    "'min_samples_leaf': min_samples_leaf,\n",
    "'bootstrap': bootstrap}\n",
    "\n",
    "#Building the random forest models for each condition without setting internal parameters manually\n",
    "\n",
    "RF_classifier_d = RandomForestClassifier(random_state=42)\n",
    "RF_classifier_d.fit(dd_X_train, dd_y_train.ravel())\n",
    "dd_y_predict = RF_classifier_d.predict(dd_X_test)\n",
    "print('Random Forest Accuracy for diabetes: {0:0.4f}'. format(accuracy_score(dd_y_test, dd_y_predict)))\n",
    "\n",
    "\n",
    "RF_classifier_h = RandomForestClassifier(random_state=42)\n",
    "RF_classifier_h.fit(hd_X_train, hd_y_train.ravel())\n",
    "hd_y_predict = RF_classifier_h.predict(hd_X_test)\n",
    "print('Random Forest Accuracy for hypertension: {0:0.4f}'. format(accuracy_score(hd_y_test, hd_y_predict)))\n",
    "\n",
    "\n",
    "RF_classifier_s = RandomForestClassifier(random_state=42)\n",
    "RF_classifier_s.fit(sd_X_train, sd_y_train.ravel())\n",
    "sd_y_predict = RF_classifier_s.predict(sd_X_test)\n",
    "print('Random Forest Accuracy for stroke: {0:0.4f}'. format(accuracy_score(sd_y_test, sd_y_predict)))\n",
    "\n",
    "\n",
    "#Running the Random Seacrh in order to find, for each dataset, the best parameters of the random\n",
    "#trees in order to obtain the best predictions.\n",
    "\n",
    "RF_classifier_d = RandomForestClassifier(random_state=42)\n",
    "RF_Search_Params_d = RandomizedSearchCV(estimator = RF_classifier_d, param_distributions = grid,\n",
    "               n_iter = 40, verbose=1, random_state=42)\n",
    "RF_Search_Params_d.fit(dd_X_train, dd_y_train.ravel())\n",
    "print ('Best RF parameters for diabetes: ', RF_Search_Params_d.best_params_, ' \\n')\n",
    "\n",
    "\n",
    "RF_classifier_h = RandomForestClassifier(random_state=42)\n",
    "RF_Search_Params_h = RandomizedSearchCV(estimator = RF_classifier_h, param_distributions = grid,\n",
    "               n_iter =40, verbose=1, random_state=42)\n",
    "RF_Search_Params_h.fit(hd_X_train, hd_y_train.ravel())\n",
    "print ('Best RF parameters for hypertension: ', RF_Search_Params_h.best_params_, ' \\n')\n",
    "\n",
    "\n",
    "RF_classifier_s = RandomForestClassifier(random_state=42)\n",
    "RF_Search_Params_s = RandomizedSearchCV(estimator = RF_classifier_s, param_distributions = grid,\n",
    "               n_iter = 40, verbose=1, random_state=42)\n",
    "RF_Search_Params_s.fit(sd_X_train, sd_y_train.ravel())\n",
    "print ('Best RF parameters for stroke: ', RF_Search_Params_s.best_params_, ' \\n')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "b0c19bfa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Improved Accuracy for diabetes: 0.7494\n",
      "Random Forest Improved Accuracy for hypertension: 1.0000\n",
      "Random Forest Improved Accuracy for stroke: 0.9978\n"
     ]
    }
   ],
   "source": [
    "#Re-running the random trees modeling now using the best parameters found previously.\n",
    "\n",
    "RF_classifier_d = RandomForestClassifier(n_estimators = 150, min_samples_split = 14, min_samples_leaf= 6, \n",
    "                                         max_features = 'auto', max_depth= 120, bootstrap=True, random_state=42)\n",
    "RF_classifier_d.fit(dd_X_train, dd_y_train.ravel())\n",
    "dd_y_predict = RF_classifier_d.predict(dd_X_test)\n",
    "print('Random Forest Improved Accuracy for diabetes: {0:0.4f}'. format(accuracy_score(dd_y_test, dd_y_predict)))\n",
    "\n",
    "\n",
    "RF_classifier_h = RandomForestClassifier(n_estimators = 50, min_samples_split = 14, min_samples_leaf= 1, \n",
    "                                         max_features = 'sqrt', max_depth= 40, bootstrap=True, random_state=42)\n",
    "RF_classifier_h.fit(hd_X_train, hd_y_train.ravel())\n",
    "hd_y_predict = RF_classifier_h.predict(hd_X_test)\n",
    "print('Random Forest Improved Accuracy for hypertension: {0:0.4f}'. format(accuracy_score(hd_y_test, hd_y_predict)))\n",
    "\n",
    "\n",
    "RF_classifier_s = RandomForestClassifier(n_estimators = 200, min_samples_split = 6, min_samples_leaf= 1, \n",
    "                                         max_features = 'auto', max_depth= 100, bootstrap=False, random_state=42)\n",
    "RF_classifier_s.fit(sd_X_train, sd_y_train.ravel())\n",
    "sd_y_predict = RF_classifier_s.predict(sd_X_test)\n",
    "print('Random Forest Improved Accuracy for stroke: {0:0.4f}'. format(accuracy_score(sd_y_test, sd_y_predict)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "174ef216",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
